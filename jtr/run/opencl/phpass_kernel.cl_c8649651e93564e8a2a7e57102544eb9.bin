//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 8.6
.target sm_86, texmode_independent
.address_size 64

	// .globl	phpass
// phpass_$_lengths has been demoted

.entry phpass(
	.param .u64 .ptr .global .align 4 phpass_param_0,
	.param .u64 .ptr .global .align 4 phpass_param_1,
	.param .u64 .ptr .global .align 4 phpass_param_2
)
{
	.local .align 8 .b8 	__local_depot0[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<21>;
	.reg .b32 	%r<3559>;
	.reg .b64 	%rd<27>;
	// demoted variable
	.shared .align 4 .b8 phpass_$_lengths[4096];

	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd7, [phpass_param_0];
	ld.param.u64 	%rd2, [phpass_param_2];
	mov.u32 	%r204, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r205, %tid.x;
	mov.b32 	%r206, %envreg3;
	add.s32 	%r207, %r205, %r206;
	mad.lo.s32 	%r208, %r1, %r204, %r207;
	cvt.u64.u32 	%rd1, %r208;
	ld.global.u32 	%r2, [%rd2+8];
	mul.wide.u32 	%rd8, %r208, 44;
	add.s64 	%rd9, %rd7, %rd8;
	add.s64 	%rd3, %rd9, 40;
	ld.global.u32 	%r3, [%rd9+40];
	cvt.s64.s32 	%rd4, %r205;
	and.b64  	%rd10, %rd4, 4294966272;
	setp.ne.s64 	%p1, %rd10, 0;
	@%p1 bra 	$L__BB0_2;

	shl.b64 	%rd11, %rd4, 2;
	and.b64  	%rd12, %rd11, 17179869180;
	mov.u64 	%rd13, phpass_$_lengths;
	add.s64 	%rd14, %rd13, %rd12;
	st.shared.u32 	[%rd14], %r3;

$L__BB0_2:
	cvt.u32.u64 	%r209, %rd4;
	and.b32  	%r210, %r1, -1024;
	setp.eq.s32 	%p2, %r210, 0;
	selp.b32 	%r211, %r1, 1024, %p2;
	bar.sync 	0;
	and.b32  	%r3518, %r209, -64;
	add.s32 	%r212, %r3518, 64;
	min.u32 	%r5, %r212, %r211;
	setp.ge.u32 	%p3, %r3518, %r5;
	setp.eq.s32 	%p4, %r2, 2;
	or.pred  	%p5, %p4, %p3;
	mov.u32 	%r3521, %r3;
	mov.u32 	%r3522, %r3;
	@%p5 bra 	$L__BB0_8;

	mov.u64 	%rd16, phpass_$_lengths;
	mov.u32 	%r3522, %r3;
	mov.u32 	%r3521, %r3;

$L__BB0_4:
	mul.wide.u32 	%rd15, %r3518, 4;
	add.s64 	%rd17, %rd16, %rd15;
	ld.shared.u32 	%r9, [%rd17];
	setp.eq.s32 	%p6, %r9, %r3;
	@%p6 bra 	$L__BB0_7;

	setp.le.u32 	%p7, %r9, %r3521;
	mov.u32 	%r3522, 0;
	@%p7 bra 	$L__BB0_7;

	setp.gt.u32 	%p8, %r9, 15;
	mov.u32 	%r3522, 0;
	mov.u32 	%r3521, %r9;
	@%p8 bra 	$L__BB0_8;

$L__BB0_7:
	add.s32 	%r3518, %r3518, 1;
	setp.lt.u32 	%p9, %r3518, %r5;
	@%p9 bra 	$L__BB0_4;

$L__BB0_8:
	add.u64 	%rd5, %SPL, 0;
	mov.u64 	%rd19, 0;
	ld.global.u32 	%r464, [%rd2+4];
	ld.global.u32 	%r465, [%rd2];
	st.local.v2.u32 	[%rd5], {%r465, %r464};
	ld.global.u32 	%r466, [%rd3+-36];
	ld.global.u32 	%r467, [%rd3+-40];
	st.local.v2.u32 	[%rd5+8], {%r467, %r466};
	ld.global.u32 	%r468, [%rd3+-28];
	ld.global.u32 	%r469, [%rd3+-32];
	st.local.v2.u32 	[%rd5+16], {%r469, %r468};
	ld.global.u32 	%r470, [%rd3+-20];
	ld.global.u32 	%r471, [%rd3+-24];
	st.local.v2.u32 	[%rd5+24], {%r471, %r470};
	ld.global.u32 	%r472, [%rd3+-12];
	ld.global.u32 	%r473, [%rd3+-16];
	st.local.v2.u32 	[%rd5+32], {%r473, %r472};
	ld.global.u32 	%r474, [%rd3+-4];
	ld.global.u32 	%r475, [%rd3+-8];
	st.local.v2.u32 	[%rd5+40], {%r475, %r474};
	st.local.u64 	[%rd5+48], %rd19;
	add.s32 	%r476, %r3, 8;
	shl.b32 	%r477, %r476, 3;
	and.b32  	%r478, %r477, 24;
	mov.u32 	%r479, 128;
	shl.b32 	%r480, %r479, %r478;
	and.b32  	%r481, %r476, -4;
	cvt.u64.u32 	%rd20, %r481;
	add.s64 	%rd21, %rd5, %rd20;
	ld.local.u32 	%r482, [%rd21];
	or.b32  	%r483, %r482, %r480;
	st.local.u32 	[%rd21], %r483;
	ld.local.v2.u32 	{%r484, %r485}, [%rd5];
	add.s32 	%r488, %r484, -680876937;
	shf.l.wrap.b32 	%r489, %r488, %r488, 7;
	add.s32 	%r223, %r489, -271733879;
	mov.u32 	%r219, -271733879;
	and.b32  	%r490, %r223, 2004318071;
	xor.b32  	%r491, %r490, -1732584194;
	add.s32 	%r492, %r485, %r491;
	add.s32 	%r493, %r492, -117830708;
	shf.l.wrap.b32 	%r494, %r493, %r493, 12;
	add.s32 	%r227, %r494, %r223;
	// begin inline asm
	lop3.b32 %r216, %r227, %r223, %r219, 202;
	// end inline asm
	ld.local.v2.u32 	{%r495, %r496}, [%rd5+8];
	add.s32 	%r499, %r216, %r495;
	add.s32 	%r500, %r499, -1126478375;
	shf.l.wrap.b32 	%r501, %r500, %r500, 17;
	add.s32 	%r231, %r227, %r501;
	// begin inline asm
	lop3.b32 %r220, %r231, %r227, %r223, 202;
	// end inline asm
	add.s32 	%r502, %r220, %r496;
	add.s32 	%r503, %r502, -1316259209;
	shf.l.wrap.b32 	%r504, %r503, %r503, 22;
	add.s32 	%r235, %r231, %r504;
	ld.local.v2.u32 	{%r505, %r506}, [%rd5+16];
	// begin inline asm
	lop3.b32 %r224, %r235, %r231, %r227, 202;
	// end inline asm
	add.s32 	%r509, %r489, %r505;
	add.s32 	%r510, %r509, %r224;
	add.s32 	%r511, %r510, -448152776;
	shf.l.wrap.b32 	%r512, %r511, %r511, 7;
	add.s32 	%r239, %r512, %r235;
	// begin inline asm
	lop3.b32 %r228, %r239, %r235, %r231, 202;
	// end inline asm
	add.s32 	%r513, %r506, %r227;
	add.s32 	%r514, %r513, %r228;
	add.s32 	%r515, %r514, 1200080426;
	shf.l.wrap.b32 	%r516, %r515, %r515, 12;
	add.s32 	%r243, %r516, %r239;
	ld.local.v2.u32 	{%r517, %r518}, [%rd5+24];
	// begin inline asm
	lop3.b32 %r232, %r243, %r239, %r235, 202;
	// end inline asm
	add.s32 	%r521, %r231, %r517;
	add.s32 	%r522, %r521, %r232;
	add.s32 	%r523, %r522, -1473231341;
	shf.l.wrap.b32 	%r524, %r523, %r523, 17;
	add.s32 	%r247, %r524, %r243;
	// begin inline asm
	lop3.b32 %r236, %r247, %r243, %r239, 202;
	// end inline asm
	add.s32 	%r525, %r235, %r518;
	add.s32 	%r526, %r525, %r236;
	add.s32 	%r527, %r526, -45705983;
	shf.l.wrap.b32 	%r528, %r527, %r527, 22;
	add.s32 	%r251, %r528, %r247;
	ld.local.v2.u32 	{%r529, %r530}, [%rd5+32];
	// begin inline asm
	lop3.b32 %r240, %r251, %r247, %r243, 202;
	// end inline asm
	add.s32 	%r533, %r239, %r529;
	add.s32 	%r534, %r533, %r240;
	add.s32 	%r535, %r534, 1770035416;
	shf.l.wrap.b32 	%r536, %r535, %r535, 7;
	add.s32 	%r255, %r536, %r251;
	// begin inline asm
	lop3.b32 %r244, %r255, %r251, %r247, 202;
	// end inline asm
	add.s32 	%r537, %r243, %r530;
	add.s32 	%r538, %r537, %r244;
	add.s32 	%r539, %r538, -1958414417;
	shf.l.wrap.b32 	%r540, %r539, %r539, 12;
	add.s32 	%r259, %r540, %r255;
	ld.local.v2.u32 	{%r541, %r542}, [%rd5+40];
	// begin inline asm
	lop3.b32 %r248, %r259, %r255, %r251, 202;
	// end inline asm
	add.s32 	%r545, %r247, %r541;
	add.s32 	%r546, %r545, %r248;
	add.s32 	%r547, %r546, -42063;
	shf.l.wrap.b32 	%r548, %r547, %r547, 17;
	add.s32 	%r263, %r548, %r259;
	// begin inline asm
	lop3.b32 %r252, %r263, %r259, %r255, 202;
	// end inline asm
	add.s32 	%r549, %r251, %r542;
	add.s32 	%r550, %r549, %r252;
	add.s32 	%r551, %r550, -1990404162;
	shf.l.wrap.b32 	%r552, %r551, %r551, 22;
	add.s32 	%r267, %r552, %r263;
	ld.local.v2.u32 	{%r553, %r554}, [%rd5+48];
	// begin inline asm
	lop3.b32 %r256, %r267, %r263, %r259, 202;
	// end inline asm
	add.s32 	%r557, %r255, %r553;
	add.s32 	%r558, %r557, %r256;
	add.s32 	%r559, %r558, 1804603682;
	shf.l.wrap.b32 	%r560, %r559, %r559, 7;
	add.s32 	%r271, %r560, %r267;
	// begin inline asm
	lop3.b32 %r260, %r271, %r267, %r263, 202;
	// end inline asm
	add.s32 	%r561, %r259, %r554;
	add.s32 	%r562, %r561, %r260;
	add.s32 	%r563, %r562, -40341101;
	shf.l.wrap.b32 	%r564, %r563, %r563, 12;
	add.s32 	%r275, %r564, %r271;
	// begin inline asm
	lop3.b32 %r264, %r275, %r271, %r267, 202;
	// end inline asm
	add.s32 	%r565, %r477, %r263;
	add.s32 	%r566, %r565, %r264;
	add.s32 	%r567, %r566, -1502002290;
	shf.l.wrap.b32 	%r568, %r567, %r567, 17;
	add.s32 	%r279, %r275, %r568;
	// begin inline asm
	lop3.b32 %r268, %r279, %r275, %r271, 202;
	// end inline asm
	add.s32 	%r569, %r267, %r268;
	add.s32 	%r570, %r569, 1236535329;
	shf.l.wrap.b32 	%r571, %r570, %r570, 22;
	add.s32 	%r283, %r279, %r571;
	// begin inline asm
	lop3.b32 %r272, %r283, %r279, %r275, 228;
	// end inline asm
	add.s32 	%r572, %r271, %r485;
	add.s32 	%r573, %r572, %r272;
	add.s32 	%r574, %r573, -165796510;
	shf.l.wrap.b32 	%r575, %r574, %r574, 5;
	add.s32 	%r287, %r575, %r283;
	// begin inline asm
	lop3.b32 %r276, %r287, %r283, %r279, 228;
	// end inline asm
	add.s32 	%r576, %r275, %r517;
	add.s32 	%r577, %r576, %r276;
	add.s32 	%r578, %r577, -1069501632;
	shf.l.wrap.b32 	%r579, %r578, %r578, 9;
	add.s32 	%r291, %r579, %r287;
	// begin inline asm
	lop3.b32 %r280, %r291, %r287, %r283, 228;
	// end inline asm
	add.s32 	%r580, %r279, %r542;
	add.s32 	%r581, %r580, %r280;
	add.s32 	%r582, %r581, 643717713;
	shf.l.wrap.b32 	%r583, %r582, %r582, 14;
	add.s32 	%r295, %r583, %r291;
	// begin inline asm
	lop3.b32 %r284, %r295, %r291, %r287, 228;
	// end inline asm
	add.s32 	%r584, %r283, %r484;
	add.s32 	%r585, %r584, %r284;
	add.s32 	%r586, %r585, -373897302;
	shf.l.wrap.b32 	%r587, %r586, %r586, 20;
	add.s32 	%r299, %r587, %r295;
	// begin inline asm
	lop3.b32 %r288, %r299, %r295, %r291, 228;
	// end inline asm
	add.s32 	%r588, %r287, %r506;
	add.s32 	%r589, %r588, %r288;
	add.s32 	%r590, %r589, -701558691;
	shf.l.wrap.b32 	%r591, %r590, %r590, 5;
	add.s32 	%r303, %r591, %r299;
	// begin inline asm
	lop3.b32 %r292, %r303, %r299, %r295, 228;
	// end inline asm
	add.s32 	%r592, %r291, %r541;
	add.s32 	%r593, %r592, %r292;
	add.s32 	%r594, %r593, 38016083;
	shf.l.wrap.b32 	%r595, %r594, %r594, 9;
	add.s32 	%r307, %r595, %r303;
	// begin inline asm
	lop3.b32 %r296, %r307, %r303, %r299, 228;
	// end inline asm
	add.s32 	%r596, %r295, %r296;
	add.s32 	%r597, %r596, -660478335;
	shf.l.wrap.b32 	%r598, %r597, %r597, 14;
	add.s32 	%r311, %r307, %r598;
	// begin inline asm
	lop3.b32 %r300, %r311, %r307, %r303, 228;
	// end inline asm
	add.s32 	%r599, %r299, %r505;
	add.s32 	%r600, %r599, %r300;
	add.s32 	%r601, %r600, -405537848;
	shf.l.wrap.b32 	%r602, %r601, %r601, 20;
	add.s32 	%r315, %r602, %r311;
	// begin inline asm
	lop3.b32 %r304, %r315, %r311, %r307, 228;
	// end inline asm
	add.s32 	%r603, %r303, %r530;
	add.s32 	%r604, %r603, %r304;
	add.s32 	%r605, %r604, 568446438;
	shf.l.wrap.b32 	%r606, %r605, %r605, 5;
	add.s32 	%r319, %r606, %r315;
	// begin inline asm
	lop3.b32 %r308, %r319, %r315, %r311, 228;
	// end inline asm
	add.s32 	%r607, %r477, %r307;
	add.s32 	%r608, %r607, %r308;
	add.s32 	%r609, %r608, -1019803690;
	shf.l.wrap.b32 	%r610, %r609, %r609, 9;
	add.s32 	%r323, %r319, %r610;
	// begin inline asm
	lop3.b32 %r312, %r323, %r319, %r315, 228;
	// end inline asm
	add.s32 	%r611, %r311, %r496;
	add.s32 	%r612, %r611, %r312;
	add.s32 	%r613, %r612, -187363961;
	shf.l.wrap.b32 	%r614, %r613, %r613, 14;
	add.s32 	%r327, %r614, %r323;
	// begin inline asm
	lop3.b32 %r316, %r327, %r323, %r319, 228;
	// end inline asm
	add.s32 	%r615, %r315, %r529;
	add.s32 	%r616, %r615, %r316;
	add.s32 	%r617, %r616, 1163531501;
	shf.l.wrap.b32 	%r618, %r617, %r617, 20;
	add.s32 	%r331, %r618, %r327;
	// begin inline asm
	lop3.b32 %r320, %r331, %r327, %r323, 228;
	// end inline asm
	add.s32 	%r619, %r319, %r554;
	add.s32 	%r620, %r619, %r320;
	add.s32 	%r621, %r620, -1444681467;
	shf.l.wrap.b32 	%r622, %r621, %r621, 5;
	add.s32 	%r335, %r622, %r331;
	// begin inline asm
	lop3.b32 %r324, %r335, %r331, %r327, 228;
	// end inline asm
	add.s32 	%r623, %r323, %r495;
	add.s32 	%r624, %r623, %r324;
	add.s32 	%r625, %r624, -51403784;
	shf.l.wrap.b32 	%r626, %r625, %r625, 9;
	add.s32 	%r339, %r626, %r335;
	// begin inline asm
	lop3.b32 %r328, %r339, %r335, %r331, 228;
	// end inline asm
	add.s32 	%r627, %r327, %r518;
	add.s32 	%r628, %r627, %r328;
	add.s32 	%r629, %r628, 1735328473;
	shf.l.wrap.b32 	%r630, %r629, %r629, 14;
	add.s32 	%r343, %r630, %r339;
	// begin inline asm
	lop3.b32 %r332, %r343, %r339, %r335, 228;
	// end inline asm
	add.s32 	%r631, %r331, %r553;
	add.s32 	%r632, %r631, %r332;
	add.s32 	%r633, %r632, -1926607734;
	shf.l.wrap.b32 	%r634, %r633, %r633, 20;
	add.s32 	%r347, %r634, %r343;
	// begin inline asm
	lop3.b32 %r336, %r347, %r343, %r339, 150;
	// end inline asm
	add.s32 	%r635, %r335, %r506;
	add.s32 	%r636, %r635, %r336;
	add.s32 	%r637, %r636, -378558;
	shf.l.wrap.b32 	%r638, %r637, %r637, 4;
	add.s32 	%r351, %r638, %r347;
	// begin inline asm
	lop3.b32 %r340, %r351, %r347, %r343, 150;
	// end inline asm
	add.s32 	%r639, %r339, %r529;
	add.s32 	%r640, %r639, %r340;
	add.s32 	%r641, %r640, -2022574463;
	shf.l.wrap.b32 	%r642, %r641, %r641, 11;
	add.s32 	%r355, %r642, %r351;
	// begin inline asm
	lop3.b32 %r344, %r355, %r351, %r347, 150;
	// end inline asm
	add.s32 	%r643, %r343, %r542;
	add.s32 	%r644, %r643, %r344;
	add.s32 	%r645, %r644, 1839030562;
	shf.l.wrap.b32 	%r646, %r645, %r645, 16;
	add.s32 	%r359, %r646, %r355;
	// begin inline asm
	lop3.b32 %r348, %r359, %r355, %r351, 150;
	// end inline asm
	add.s32 	%r647, %r477, %r347;
	add.s32 	%r648, %r647, %r348;
	add.s32 	%r649, %r648, -35309556;
	shf.l.wrap.b32 	%r650, %r649, %r649, 23;
	add.s32 	%r363, %r359, %r650;
	// begin inline asm
	lop3.b32 %r352, %r363, %r359, %r355, 150;
	// end inline asm
	add.s32 	%r651, %r351, %r485;
	add.s32 	%r652, %r651, %r352;
	add.s32 	%r653, %r652, -1530992060;
	shf.l.wrap.b32 	%r654, %r653, %r653, 4;
	add.s32 	%r367, %r654, %r363;
	// begin inline asm
	lop3.b32 %r356, %r367, %r363, %r359, 150;
	// end inline asm
	add.s32 	%r655, %r355, %r505;
	add.s32 	%r656, %r655, %r356;
	add.s32 	%r657, %r656, 1272893353;
	shf.l.wrap.b32 	%r658, %r657, %r657, 11;
	add.s32 	%r371, %r658, %r367;
	// begin inline asm
	lop3.b32 %r360, %r371, %r367, %r363, 150;
	// end inline asm
	add.s32 	%r659, %r359, %r518;
	add.s32 	%r660, %r659, %r360;
	add.s32 	%r661, %r660, -155497632;
	shf.l.wrap.b32 	%r662, %r661, %r661, 16;
	add.s32 	%r375, %r662, %r371;
	// begin inline asm
	lop3.b32 %r364, %r375, %r371, %r367, 150;
	// end inline asm
	add.s32 	%r663, %r363, %r541;
	add.s32 	%r664, %r663, %r364;
	add.s32 	%r665, %r664, -1094730640;
	shf.l.wrap.b32 	%r666, %r665, %r665, 23;
	add.s32 	%r379, %r666, %r375;
	// begin inline asm
	lop3.b32 %r368, %r379, %r375, %r371, 150;
	// end inline asm
	add.s32 	%r667, %r367, %r554;
	add.s32 	%r668, %r667, %r368;
	add.s32 	%r669, %r668, 681279174;
	shf.l.wrap.b32 	%r670, %r669, %r669, 4;
	add.s32 	%r383, %r670, %r379;
	// begin inline asm
	lop3.b32 %r372, %r383, %r379, %r375, 150;
	// end inline asm
	add.s32 	%r671, %r371, %r484;
	add.s32 	%r672, %r671, %r372;
	add.s32 	%r673, %r672, -358537222;
	shf.l.wrap.b32 	%r674, %r673, %r673, 11;
	add.s32 	%r387, %r674, %r383;
	// begin inline asm
	lop3.b32 %r376, %r387, %r383, %r379, 150;
	// end inline asm
	add.s32 	%r675, %r375, %r496;
	add.s32 	%r676, %r675, %r376;
	add.s32 	%r677, %r676, -722521979;
	shf.l.wrap.b32 	%r678, %r677, %r677, 16;
	add.s32 	%r391, %r678, %r387;
	// begin inline asm
	lop3.b32 %r380, %r391, %r387, %r383, 150;
	// end inline asm
	add.s32 	%r679, %r379, %r517;
	add.s32 	%r680, %r679, %r380;
	add.s32 	%r681, %r680, 76029189;
	shf.l.wrap.b32 	%r682, %r681, %r681, 23;
	add.s32 	%r395, %r682, %r391;
	// begin inline asm
	lop3.b32 %r384, %r395, %r391, %r387, 150;
	// end inline asm
	add.s32 	%r683, %r383, %r530;
	add.s32 	%r684, %r683, %r384;
	add.s32 	%r685, %r684, -640364487;
	shf.l.wrap.b32 	%r686, %r685, %r685, 4;
	add.s32 	%r399, %r686, %r395;
	// begin inline asm
	lop3.b32 %r388, %r399, %r395, %r391, 150;
	// end inline asm
	add.s32 	%r687, %r387, %r553;
	add.s32 	%r688, %r687, %r388;
	add.s32 	%r689, %r688, -421815835;
	shf.l.wrap.b32 	%r690, %r689, %r689, 11;
	add.s32 	%r403, %r690, %r399;
	// begin inline asm
	lop3.b32 %r392, %r403, %r399, %r395, 150;
	// end inline asm
	add.s32 	%r691, %r391, %r392;
	add.s32 	%r692, %r691, 530742520;
	shf.l.wrap.b32 	%r693, %r692, %r692, 16;
	add.s32 	%r407, %r403, %r693;
	// begin inline asm
	lop3.b32 %r396, %r407, %r403, %r399, 150;
	// end inline asm
	add.s32 	%r694, %r395, %r495;
	add.s32 	%r695, %r694, %r396;
	add.s32 	%r696, %r695, -995338651;
	shf.l.wrap.b32 	%r697, %r696, %r696, 23;
	add.s32 	%r411, %r697, %r407;
	// begin inline asm
	lop3.b32 %r400, %r411, %r407, %r403, 57;
	// end inline asm
	add.s32 	%r698, %r399, %r484;
	add.s32 	%r699, %r698, %r400;
	add.s32 	%r700, %r699, -198630844;
	shf.l.wrap.b32 	%r701, %r700, %r700, 6;
	add.s32 	%r415, %r701, %r411;
	// begin inline asm
	lop3.b32 %r404, %r415, %r411, %r407, 57;
	// end inline asm
	add.s32 	%r702, %r403, %r518;
	add.s32 	%r703, %r702, %r404;
	add.s32 	%r704, %r703, 1126891415;
	shf.l.wrap.b32 	%r705, %r704, %r704, 10;
	add.s32 	%r419, %r705, %r415;
	// begin inline asm
	lop3.b32 %r408, %r419, %r415, %r411, 57;
	// end inline asm
	add.s32 	%r706, %r477, %r407;
	add.s32 	%r707, %r706, %r408;
	add.s32 	%r708, %r707, -1416354905;
	shf.l.wrap.b32 	%r709, %r708, %r708, 15;
	add.s32 	%r423, %r419, %r709;
	// begin inline asm
	lop3.b32 %r412, %r423, %r419, %r415, 57;
	// end inline asm
	add.s32 	%r710, %r411, %r506;
	add.s32 	%r711, %r710, %r412;
	add.s32 	%r712, %r711, -57434055;
	shf.l.wrap.b32 	%r713, %r712, %r712, 21;
	add.s32 	%r427, %r713, %r423;
	// begin inline asm
	lop3.b32 %r416, %r427, %r423, %r419, 57;
	// end inline asm
	add.s32 	%r714, %r415, %r553;
	add.s32 	%r715, %r714, %r416;
	add.s32 	%r716, %r715, 1700485571;
	shf.l.wrap.b32 	%r717, %r716, %r716, 6;
	add.s32 	%r431, %r717, %r427;
	// begin inline asm
	lop3.b32 %r420, %r431, %r427, %r423, 57;
	// end inline asm
	add.s32 	%r718, %r419, %r496;
	add.s32 	%r719, %r718, %r420;
	add.s32 	%r720, %r719, -1894986606;
	shf.l.wrap.b32 	%r721, %r720, %r720, 10;
	add.s32 	%r435, %r721, %r431;
	// begin inline asm
	lop3.b32 %r424, %r435, %r431, %r427, 57;
	// end inline asm
	add.s32 	%r722, %r423, %r541;
	add.s32 	%r723, %r722, %r424;
	add.s32 	%r724, %r723, -1051523;
	shf.l.wrap.b32 	%r725, %r724, %r724, 15;
	add.s32 	%r439, %r725, %r435;
	// begin inline asm
	lop3.b32 %r428, %r439, %r435, %r431, 57;
	// end inline asm
	add.s32 	%r726, %r427, %r485;
	add.s32 	%r727, %r726, %r428;
	add.s32 	%r728, %r727, -2054922799;
	shf.l.wrap.b32 	%r729, %r728, %r728, 21;
	add.s32 	%r443, %r729, %r439;
	// begin inline asm
	lop3.b32 %r432, %r443, %r439, %r435, 57;
	// end inline asm
	add.s32 	%r730, %r431, %r529;
	add.s32 	%r731, %r730, %r432;
	add.s32 	%r732, %r731, 1873313359;
	shf.l.wrap.b32 	%r733, %r732, %r732, 6;
	add.s32 	%r447, %r733, %r443;
	// begin inline asm
	lop3.b32 %r436, %r447, %r443, %r439, 57;
	// end inline asm
	add.s32 	%r734, %r435, %r436;
	add.s32 	%r735, %r734, -30611744;
	shf.l.wrap.b32 	%r736, %r735, %r735, 10;
	add.s32 	%r451, %r447, %r736;
	// begin inline asm
	lop3.b32 %r440, %r451, %r447, %r443, 57;
	// end inline asm
	add.s32 	%r737, %r439, %r517;
	add.s32 	%r738, %r737, %r440;
	add.s32 	%r739, %r738, -1560198380;
	shf.l.wrap.b32 	%r740, %r739, %r739, 15;
	add.s32 	%r455, %r740, %r451;
	// begin inline asm
	lop3.b32 %r444, %r455, %r451, %r447, 57;
	// end inline asm
	add.s32 	%r741, %r443, %r554;
	add.s32 	%r742, %r741, %r444;
	add.s32 	%r743, %r742, 1309151649;
	shf.l.wrap.b32 	%r744, %r743, %r743, 21;
	add.s32 	%r459, %r744, %r455;
	// begin inline asm
	lop3.b32 %r448, %r459, %r455, %r451, 57;
	// end inline asm
	add.s32 	%r745, %r447, %r505;
	add.s32 	%r746, %r745, %r448;
	add.s32 	%r747, %r746, -145523070;
	shf.l.wrap.b32 	%r748, %r747, %r747, 6;
	add.s32 	%r463, %r748, %r459;
	// begin inline asm
	lop3.b32 %r452, %r463, %r459, %r455, 57;
	// end inline asm
	add.s32 	%r749, %r451, %r542;
	add.s32 	%r750, %r749, %r452;
	add.s32 	%r751, %r750, -1120210379;
	shf.l.wrap.b32 	%r752, %r751, %r751, 10;
	add.s32 	%r462, %r752, %r463;
	// begin inline asm
	lop3.b32 %r456, %r462, %r463, %r459, 57;
	// end inline asm
	add.s32 	%r753, %r455, %r495;
	add.s32 	%r754, %r753, %r456;
	add.s32 	%r755, %r754, 718787259;
	shf.l.wrap.b32 	%r756, %r755, %r755, 15;
	add.s32 	%r461, %r756, %r462;
	// begin inline asm
	lop3.b32 %r460, %r461, %r462, %r463, 57;
	// end inline asm
	add.s32 	%r757, %r459, %r530;
	add.s32 	%r758, %r757, %r460;
	add.s32 	%r759, %r758, -343485551;
	shf.l.wrap.b32 	%r760, %r759, %r759, 21;
	add.s32 	%r761, %r461, %r760;
	add.s32 	%r762, %r761, -271733879;
	add.s32 	%r763, %r463, 1732584193;
	st.local.v2.u32 	[%rd5], {%r763, %r762};
	add.s32 	%r764, %r461, -1732584194;
	add.s32 	%r765, %r462, 271733878;
	st.local.v2.u32 	[%rd5+8], {%r764, %r765};
	st.local.v2.u32 	[%rd5+16], {%r467, %r466};
	st.local.v2.u32 	[%rd5+24], {%r469, %r468};
	st.local.v2.u32 	[%rd5+32], {%r471, %r470};
	st.local.v2.u32 	[%rd5+40], {%r473, %r472};
	st.local.v2.u32 	[%rd5+48], {%r475, %r474};
	add.s32 	%r766, %r3, 16;
	shl.b32 	%r15, %r766, 3;
	and.b32  	%r767, %r15, 24;
	shl.b32 	%r768, %r479, %r767;
	and.b32  	%r769, %r766, -4;
	cvt.u64.u32 	%rd22, %r769;
	add.s64 	%rd23, %rd5, %rd22;
	ld.local.u32 	%r770, [%rd23];
	or.b32  	%r771, %r770, %r768;
	st.local.u32 	[%rd23], %r771;
	ld.local.v2.u32 	{%r772, %r773}, [%rd5];
	add.s32 	%r3555, %r772, -1732584193;
	add.s32 	%r3556, %r773, 271733879;
	ld.local.v2.u32 	{%r776, %r777}, [%rd5+8];
	add.s32 	%r3557, %r776, 1732584194;
	add.s32 	%r3558, %r777, -271733878;
	ld.local.v2.u32 	{%r780, %r781}, [%rd5+16];
	ld.local.v2.u32 	{%r782, %r783}, [%rd5+24];
	setp.lt.u32 	%p10, %r3521, 8;
	@%p10 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_9;

$L__BB0_23:
	add.s32 	%r178, %r780, -176418897;
	add.s32 	%r179, %r781, 1200080426;
	add.s32 	%r180, %r15, -1502002290;
	add.s32 	%r181, %r781, -701558691;
	add.s32 	%r182, %r780, -405537848;
	add.s32 	%r183, %r15, -1019803690;
	add.s32 	%r184, %r781, -378558;
	add.s32 	%r185, %r15, -35309556;
	add.s32 	%r186, %r780, 1272893353;
	add.s32 	%r187, %r15, -1416354905;
	add.s32 	%r188, %r781, -57434055;
	add.s32 	%r189, %r780, -145523070;

$L__BB0_24:
	add.s32 	%r3309, %r3555, 1051707256;
	shf.l.wrap.b32 	%r3310, %r3309, %r3309, 7;
	add.s32 	%r3068, %r3310, -271733879;
	mov.u32 	%r3064, -271733879;
	and.b32  	%r3311, %r3068, 2004318071;
	xor.b32  	%r3312, %r3311, -1732584194;
	add.s32 	%r3313, %r3556, %r3312;
	add.s32 	%r3314, %r3313, -389564587;
	shf.l.wrap.b32 	%r3315, %r3314, %r3314, 12;
	add.s32 	%r3072, %r3315, %r3068;
	// begin inline asm
	lop3.b32 %r3061, %r3072, %r3068, %r3064, 202;
	// end inline asm
	add.s32 	%r3316, %r3557, %r3061;
	add.s32 	%r3317, %r3316, 1435904727;
	shf.l.wrap.b32 	%r3318, %r3317, %r3317, 17;
	add.s32 	%r3076, %r3072, %r3318;
	// begin inline asm
	lop3.b32 %r3065, %r3076, %r3072, %r3068, 202;
	// end inline asm
	add.s32 	%r3319, %r3558, %r3065;
	add.s32 	%r3320, %r3319, -1044525331;
	shf.l.wrap.b32 	%r3321, %r3320, %r3320, 22;
	add.s32 	%r3080, %r3076, %r3321;
	// begin inline asm
	lop3.b32 %r3069, %r3080, %r3076, %r3072, 202;
	// end inline asm
	add.s32 	%r3322, %r178, %r3068;
	add.s32 	%r3323, %r3322, %r3069;
	shf.l.wrap.b32 	%r3324, %r3323, %r3323, 7;
	add.s32 	%r3084, %r3080, %r3324;
	// begin inline asm
	lop3.b32 %r3073, %r3084, %r3080, %r3076, 202;
	// end inline asm
	add.s32 	%r3325, %r179, %r3073;
	add.s32 	%r3326, %r3325, %r3072;
	shf.l.wrap.b32 	%r3327, %r3326, %r3326, 12;
	add.s32 	%r3088, %r3327, %r3084;
	// begin inline asm
	lop3.b32 %r3077, %r3088, %r3084, %r3080, 202;
	// end inline asm
	add.s32 	%r3328, %r3077, %r3076;
	add.s32 	%r3329, %r3328, -1473231341;
	shf.l.wrap.b32 	%r3330, %r3329, %r3329, 17;
	add.s32 	%r3092, %r3088, %r3330;
	// begin inline asm
	lop3.b32 %r3081, %r3092, %r3088, %r3084, 202;
	// end inline asm
	add.s32 	%r3331, %r3081, %r3080;
	add.s32 	%r3332, %r3331, -45705983;
	shf.l.wrap.b32 	%r3333, %r3332, %r3332, 22;
	add.s32 	%r3096, %r3092, %r3333;
	// begin inline asm
	lop3.b32 %r3085, %r3096, %r3092, %r3088, 202;
	// end inline asm
	add.s32 	%r3334, %r3085, %r3084;
	add.s32 	%r3335, %r3334, 1770035416;
	shf.l.wrap.b32 	%r3336, %r3335, %r3335, 7;
	add.s32 	%r3100, %r3096, %r3336;
	// begin inline asm
	lop3.b32 %r3089, %r3100, %r3096, %r3092, 202;
	// end inline asm
	add.s32 	%r3337, %r3089, %r3088;
	add.s32 	%r3338, %r3337, -1958414417;
	shf.l.wrap.b32 	%r3339, %r3338, %r3338, 12;
	add.s32 	%r3104, %r3339, %r3100;
	// begin inline asm
	lop3.b32 %r3093, %r3104, %r3100, %r3096, 202;
	// end inline asm
	add.s32 	%r3340, %r3093, %r3092;
	add.s32 	%r3341, %r3340, -42063;
	shf.l.wrap.b32 	%r3342, %r3341, %r3341, 17;
	add.s32 	%r3108, %r3342, %r3104;
	// begin inline asm
	lop3.b32 %r3097, %r3108, %r3104, %r3100, 202;
	// end inline asm
	add.s32 	%r3343, %r3097, %r3096;
	add.s32 	%r3344, %r3343, -1990404162;
	shf.l.wrap.b32 	%r3345, %r3344, %r3344, 22;
	add.s32 	%r3112, %r3345, %r3108;
	// begin inline asm
	lop3.b32 %r3101, %r3112, %r3108, %r3104, 202;
	// end inline asm
	add.s32 	%r3346, %r3101, %r3100;
	add.s32 	%r3347, %r3346, 1804603682;
	shf.l.wrap.b32 	%r3348, %r3347, %r3347, 7;
	add.s32 	%r3116, %r3348, %r3112;
	// begin inline asm
	lop3.b32 %r3105, %r3116, %r3112, %r3108, 202;
	// end inline asm
	add.s32 	%r3349, %r3105, %r3104;
	add.s32 	%r3350, %r3349, -40341101;
	shf.l.wrap.b32 	%r3351, %r3350, %r3350, 12;
	add.s32 	%r3120, %r3351, %r3116;
	// begin inline asm
	lop3.b32 %r3109, %r3120, %r3116, %r3112, 202;
	// end inline asm
	add.s32 	%r3352, %r180, %r3109;
	add.s32 	%r3353, %r3352, %r3108;
	shf.l.wrap.b32 	%r3354, %r3353, %r3353, 17;
	add.s32 	%r3124, %r3354, %r3120;
	// begin inline asm
	lop3.b32 %r3113, %r3124, %r3120, %r3116, 202;
	// end inline asm
	add.s32 	%r3355, %r3113, %r3112;
	add.s32 	%r3356, %r3355, 1236535329;
	shf.l.wrap.b32 	%r3357, %r3356, %r3356, 22;
	add.s32 	%r3128, %r3124, %r3357;
	// begin inline asm
	lop3.b32 %r3117, %r3128, %r3124, %r3120, 228;
	// end inline asm
	add.s32 	%r3358, %r3556, %r3117;
	add.s32 	%r3359, %r3358, %r3116;
	add.s32 	%r3360, %r3359, -437530389;
	shf.l.wrap.b32 	%r3361, %r3360, %r3360, 5;
	add.s32 	%r3132, %r3361, %r3128;
	// begin inline asm
	lop3.b32 %r3121, %r3132, %r3128, %r3124, 228;
	// end inline asm
	add.s32 	%r3362, %r3121, %r3120;
	add.s32 	%r3363, %r3362, -1069501632;
	shf.l.wrap.b32 	%r3364, %r3363, %r3363, 9;
	add.s32 	%r3136, %r3132, %r3364;
	// begin inline asm
	lop3.b32 %r3125, %r3136, %r3132, %r3128, 228;
	// end inline asm
	add.s32 	%r3365, %r3125, %r3124;
	add.s32 	%r3366, %r3365, 643717713;
	shf.l.wrap.b32 	%r3367, %r3366, %r3366, 14;
	add.s32 	%r3140, %r3367, %r3136;
	// begin inline asm
	lop3.b32 %r3129, %r3140, %r3136, %r3132, 228;
	// end inline asm
	add.s32 	%r3368, %r3555, %r3129;
	add.s32 	%r3369, %r3368, %r3128;
	add.s32 	%r3370, %r3369, 1358686891;
	shf.l.wrap.b32 	%r3371, %r3370, %r3370, 20;
	add.s32 	%r3144, %r3371, %r3140;
	// begin inline asm
	lop3.b32 %r3133, %r3144, %r3140, %r3136, 228;
	// end inline asm
	add.s32 	%r3372, %r181, %r3133;
	add.s32 	%r3373, %r3372, %r3132;
	shf.l.wrap.b32 	%r3374, %r3373, %r3373, 5;
	add.s32 	%r3148, %r3374, %r3144;
	// begin inline asm
	lop3.b32 %r3137, %r3148, %r3144, %r3140, 228;
	// end inline asm
	add.s32 	%r3375, %r3137, %r3136;
	add.s32 	%r3376, %r3375, 38016083;
	shf.l.wrap.b32 	%r3377, %r3376, %r3376, 9;
	add.s32 	%r3152, %r3148, %r3377;
	// begin inline asm
	lop3.b32 %r3141, %r3152, %r3148, %r3144, 228;
	// end inline asm
	add.s32 	%r3378, %r3141, %r3140;
	add.s32 	%r3379, %r3378, -660478335;
	shf.l.wrap.b32 	%r3380, %r3379, %r3379, 14;
	add.s32 	%r3156, %r3152, %r3380;
	// begin inline asm
	lop3.b32 %r3145, %r3156, %r3152, %r3148, 228;
	// end inline asm
	add.s32 	%r3381, %r182, %r3145;
	add.s32 	%r3382, %r3381, %r3144;
	shf.l.wrap.b32 	%r3383, %r3382, %r3382, 20;
	add.s32 	%r3160, %r3383, %r3156;
	// begin inline asm
	lop3.b32 %r3149, %r3160, %r3156, %r3152, 228;
	// end inline asm
	add.s32 	%r3384, %r3149, %r3148;
	add.s32 	%r3385, %r3384, 568446438;
	shf.l.wrap.b32 	%r3386, %r3385, %r3385, 5;
	add.s32 	%r3164, %r3160, %r3386;
	// begin inline asm
	lop3.b32 %r3153, %r3164, %r3160, %r3156, 228;
	// end inline asm
	add.s32 	%r3387, %r183, %r3153;
	add.s32 	%r3388, %r3387, %r3152;
	shf.l.wrap.b32 	%r3389, %r3388, %r3388, 9;
	add.s32 	%r3168, %r3389, %r3164;
	// begin inline asm
	lop3.b32 %r3157, %r3168, %r3164, %r3160, 228;
	// end inline asm
	add.s32 	%r3390, %r3558, %r3157;
	add.s32 	%r3391, %r3390, %r3156;
	add.s32 	%r3392, %r3391, 84369917;
	shf.l.wrap.b32 	%r3393, %r3392, %r3392, 14;
	add.s32 	%r3172, %r3393, %r3168;
	// begin inline asm
	lop3.b32 %r3161, %r3172, %r3168, %r3164, 228;
	// end inline asm
	add.s32 	%r3394, %r3161, %r3160;
	add.s32 	%r3395, %r3394, 1163531501;
	shf.l.wrap.b32 	%r3396, %r3395, %r3395, 20;
	add.s32 	%r3176, %r3396, %r3172;
	// begin inline asm
	lop3.b32 %r3165, %r3176, %r3172, %r3168, 228;
	// end inline asm
	add.s32 	%r3397, %r3165, %r3164;
	add.s32 	%r3398, %r3397, -1444681467;
	shf.l.wrap.b32 	%r3399, %r3398, %r3398, 5;
	add.s32 	%r3180, %r3399, %r3176;
	// begin inline asm
	lop3.b32 %r3169, %r3180, %r3176, %r3172, 228;
	// end inline asm
	add.s32 	%r3400, %r3557, %r3169;
	add.s32 	%r3401, %r3400, %r3168;
	add.s32 	%r3402, %r3401, -1783987978;
	shf.l.wrap.b32 	%r3403, %r3402, %r3402, 9;
	add.s32 	%r3184, %r3403, %r3180;
	// begin inline asm
	lop3.b32 %r3173, %r3184, %r3180, %r3176, 228;
	// end inline asm
	add.s32 	%r3404, %r3173, %r3172;
	add.s32 	%r3405, %r3404, 1735328473;
	shf.l.wrap.b32 	%r3406, %r3405, %r3405, 14;
	add.s32 	%r3188, %r3184, %r3406;
	// begin inline asm
	lop3.b32 %r3177, %r3188, %r3184, %r3180, 228;
	// end inline asm
	add.s32 	%r3407, %r3177, %r3176;
	add.s32 	%r3408, %r3407, -1926607734;
	shf.l.wrap.b32 	%r3409, %r3408, %r3408, 20;
	add.s32 	%r3192, %r3188, %r3409;
	// begin inline asm
	lop3.b32 %r3181, %r3192, %r3188, %r3184, 150;
	// end inline asm
	add.s32 	%r3410, %r184, %r3181;
	add.s32 	%r3411, %r3410, %r3180;
	shf.l.wrap.b32 	%r3412, %r3411, %r3411, 4;
	add.s32 	%r3196, %r3412, %r3192;
	// begin inline asm
	lop3.b32 %r3185, %r3196, %r3192, %r3188, 150;
	// end inline asm
	add.s32 	%r3413, %r3185, %r3184;
	add.s32 	%r3414, %r3413, -2022574463;
	shf.l.wrap.b32 	%r3415, %r3414, %r3414, 11;
	add.s32 	%r3200, %r3415, %r3196;
	// begin inline asm
	lop3.b32 %r3189, %r3200, %r3196, %r3192, 150;
	// end inline asm
	add.s32 	%r3416, %r3189, %r3188;
	add.s32 	%r3417, %r3416, 1839030562;
	shf.l.wrap.b32 	%r3418, %r3417, %r3417, 16;
	add.s32 	%r3204, %r3418, %r3200;
	// begin inline asm
	lop3.b32 %r3193, %r3204, %r3200, %r3196, 150;
	// end inline asm
	add.s32 	%r3419, %r185, %r3193;
	add.s32 	%r3420, %r3419, %r3192;
	shf.l.wrap.b32 	%r3421, %r3420, %r3420, 23;
	add.s32 	%r3208, %r3421, %r3204;
	// begin inline asm
	lop3.b32 %r3197, %r3208, %r3204, %r3200, 150;
	// end inline asm
	add.s32 	%r3422, %r3556, %r3197;
	add.s32 	%r3423, %r3422, %r3196;
	add.s32 	%r3424, %r3423, -1802725939;
	shf.l.wrap.b32 	%r3425, %r3424, %r3424, 4;
	add.s32 	%r3212, %r3425, %r3208;
	// begin inline asm
	lop3.b32 %r3201, %r3212, %r3208, %r3204, 150;
	// end inline asm
	add.s32 	%r3426, %r186, %r3201;
	add.s32 	%r3427, %r3426, %r3200;
	shf.l.wrap.b32 	%r3428, %r3427, %r3427, 11;
	add.s32 	%r3216, %r3428, %r3212;
	// begin inline asm
	lop3.b32 %r3205, %r3216, %r3212, %r3208, 150;
	// end inline asm
	add.s32 	%r3429, %r3205, %r3204;
	add.s32 	%r3430, %r3429, -155497632;
	shf.l.wrap.b32 	%r3431, %r3430, %r3430, 16;
	add.s32 	%r3220, %r3216, %r3431;
	// begin inline asm
	lop3.b32 %r3209, %r3220, %r3216, %r3212, 150;
	// end inline asm
	add.s32 	%r3432, %r3209, %r3208;
	add.s32 	%r3433, %r3432, -1094730640;
	shf.l.wrap.b32 	%r3434, %r3433, %r3433, 23;
	add.s32 	%r3224, %r3434, %r3220;
	// begin inline asm
	lop3.b32 %r3213, %r3224, %r3220, %r3216, 150;
	// end inline asm
	add.s32 	%r3435, %r3213, %r3212;
	add.s32 	%r3436, %r3435, 681279174;
	shf.l.wrap.b32 	%r3437, %r3436, %r3436, 4;
	add.s32 	%r3228, %r3437, %r3224;
	// begin inline asm
	lop3.b32 %r3217, %r3228, %r3224, %r3220, 150;
	// end inline asm
	add.s32 	%r3438, %r3555, %r3217;
	add.s32 	%r3439, %r3438, %r3216;
	add.s32 	%r3440, %r3439, 1374046971;
	shf.l.wrap.b32 	%r3441, %r3440, %r3440, 11;
	add.s32 	%r3232, %r3441, %r3228;
	// begin inline asm
	lop3.b32 %r3221, %r3232, %r3228, %r3224, 150;
	// end inline asm
	add.s32 	%r3442, %r3558, %r3221;
	add.s32 	%r3443, %r3442, %r3220;
	add.s32 	%r3444, %r3443, -450788101;
	shf.l.wrap.b32 	%r3445, %r3444, %r3444, 16;
	add.s32 	%r3236, %r3445, %r3232;
	// begin inline asm
	lop3.b32 %r3225, %r3236, %r3232, %r3228, 150;
	// end inline asm
	add.s32 	%r3446, %r3225, %r3224;
	add.s32 	%r3447, %r3446, 76029189;
	shf.l.wrap.b32 	%r3448, %r3447, %r3447, 23;
	add.s32 	%r3240, %r3236, %r3448;
	// begin inline asm
	lop3.b32 %r3229, %r3240, %r3236, %r3232, 150;
	// end inline asm
	add.s32 	%r3449, %r3229, %r3228;
	add.s32 	%r3450, %r3449, -640364487;
	shf.l.wrap.b32 	%r3451, %r3450, %r3450, 4;
	add.s32 	%r3244, %r3240, %r3451;
	// begin inline asm
	lop3.b32 %r3233, %r3244, %r3240, %r3236, 150;
	// end inline asm
	add.s32 	%r3452, %r3233, %r3232;
	add.s32 	%r3453, %r3452, -421815835;
	shf.l.wrap.b32 	%r3454, %r3453, %r3453, 11;
	add.s32 	%r3248, %r3454, %r3244;
	// begin inline asm
	lop3.b32 %r3237, %r3248, %r3244, %r3240, 150;
	// end inline asm
	add.s32 	%r3455, %r3237, %r3236;
	add.s32 	%r3456, %r3455, 530742520;
	shf.l.wrap.b32 	%r3457, %r3456, %r3456, 16;
	add.s32 	%r3252, %r3457, %r3248;
	// begin inline asm
	lop3.b32 %r3241, %r3252, %r3248, %r3244, 150;
	// end inline asm
	add.s32 	%r3458, %r3557, %r3241;
	add.s32 	%r3459, %r3458, %r3240;
	add.s32 	%r3460, %r3459, 1567044451;
	shf.l.wrap.b32 	%r3461, %r3460, %r3460, 23;
	add.s32 	%r3256, %r3461, %r3252;
	// begin inline asm
	lop3.b32 %r3245, %r3256, %r3252, %r3248, 57;
	// end inline asm
	add.s32 	%r3462, %r3555, %r3245;
	add.s32 	%r3463, %r3462, %r3244;
	add.s32 	%r3464, %r3463, 1533953349;
	shf.l.wrap.b32 	%r3465, %r3464, %r3464, 6;
	add.s32 	%r3260, %r3465, %r3256;
	// begin inline asm
	lop3.b32 %r3249, %r3260, %r3256, %r3252, 57;
	// end inline asm
	add.s32 	%r3466, %r3249, %r3248;
	add.s32 	%r3467, %r3466, 1126891415;
	shf.l.wrap.b32 	%r3468, %r3467, %r3467, 10;
	add.s32 	%r3264, %r3260, %r3468;
	// begin inline asm
	lop3.b32 %r3253, %r3264, %r3260, %r3256, 57;
	// end inline asm
	add.s32 	%r3469, %r187, %r3253;
	add.s32 	%r3470, %r3469, %r3252;
	shf.l.wrap.b32 	%r3471, %r3470, %r3470, 15;
	add.s32 	%r3268, %r3471, %r3264;
	// begin inline asm
	lop3.b32 %r3257, %r3268, %r3264, %r3260, 57;
	// end inline asm
	add.s32 	%r3472, %r188, %r3257;
	add.s32 	%r3473, %r3472, %r3256;
	shf.l.wrap.b32 	%r3474, %r3473, %r3473, 21;
	add.s32 	%r3272, %r3474, %r3268;
	// begin inline asm
	lop3.b32 %r3261, %r3272, %r3268, %r3264, 57;
	// end inline asm
	add.s32 	%r3475, %r3261, %r3260;
	add.s32 	%r3476, %r3475, 1700485571;
	shf.l.wrap.b32 	%r3477, %r3476, %r3476, 6;
	add.s32 	%r3276, %r3272, %r3477;
	// begin inline asm
	lop3.b32 %r3265, %r3276, %r3272, %r3268, 57;
	// end inline asm
	add.s32 	%r3478, %r3558, %r3265;
	add.s32 	%r3479, %r3478, %r3264;
	add.s32 	%r3480, %r3479, -1623252728;
	shf.l.wrap.b32 	%r3481, %r3480, %r3480, 10;
	add.s32 	%r3280, %r3481, %r3276;
	// begin inline asm
	lop3.b32 %r3269, %r3280, %r3276, %r3272, 57;
	// end inline asm
	add.s32 	%r3482, %r3269, %r3268;
	add.s32 	%r3483, %r3482, -1051523;
	shf.l.wrap.b32 	%r3484, %r3483, %r3483, 15;
	add.s32 	%r3284, %r3280, %r3484;
	// begin inline asm
	lop3.b32 %r3273, %r3284, %r3280, %r3276, 57;
	// end inline asm
	add.s32 	%r3485, %r3556, %r3273;
	add.s32 	%r3486, %r3485, %r3272;
	add.s32 	%r3487, %r3486, 1968310618;
	shf.l.wrap.b32 	%r3488, %r3487, %r3487, 21;
	add.s32 	%r3288, %r3488, %r3284;
	// begin inline asm
	lop3.b32 %r3277, %r3288, %r3284, %r3280, 57;
	// end inline asm
	add.s32 	%r3489, %r3277, %r3276;
	add.s32 	%r3490, %r3489, 1873313359;
	shf.l.wrap.b32 	%r3491, %r3490, %r3490, 6;
	add.s32 	%r3292, %r3288, %r3491;
	// begin inline asm
	lop3.b32 %r3281, %r3292, %r3288, %r3284, 57;
	// end inline asm
	add.s32 	%r3492, %r3281, %r3280;
	add.s32 	%r3493, %r3492, -30611744;
	shf.l.wrap.b32 	%r3494, %r3493, %r3493, 10;
	add.s32 	%r3296, %r3292, %r3494;
	// begin inline asm
	lop3.b32 %r3285, %r3296, %r3292, %r3288, 57;
	// end inline asm
	add.s32 	%r3495, %r3285, %r3284;
	add.s32 	%r3496, %r3495, -1560198380;
	shf.l.wrap.b32 	%r3497, %r3496, %r3496, 15;
	add.s32 	%r3300, %r3296, %r3497;
	// begin inline asm
	lop3.b32 %r3289, %r3300, %r3296, %r3292, 57;
	// end inline asm
	add.s32 	%r3498, %r3289, %r3288;
	add.s32 	%r3499, %r3498, 1309151649;
	shf.l.wrap.b32 	%r3500, %r3499, %r3499, 21;
	add.s32 	%r3304, %r3500, %r3300;
	// begin inline asm
	lop3.b32 %r3293, %r3304, %r3300, %r3296, 57;
	// end inline asm
	add.s32 	%r3501, %r189, %r3293;
	add.s32 	%r3502, %r3501, %r3292;
	shf.l.wrap.b32 	%r3503, %r3502, %r3502, 6;
	add.s32 	%r3555, %r3503, %r3304;
	// begin inline asm
	lop3.b32 %r3297, %r3555, %r3304, %r3300, 57;
	// end inline asm
	add.s32 	%r3504, %r3297, %r3296;
	add.s32 	%r3505, %r3504, -1120210379;
	shf.l.wrap.b32 	%r3506, %r3505, %r3505, 10;
	add.s32 	%r3558, %r3555, %r3506;
	// begin inline asm
	lop3.b32 %r3301, %r3558, %r3555, %r3304, 57;
	// end inline asm
	add.s32 	%r3507, %r3557, %r3301;
	add.s32 	%r3508, %r3507, %r3300;
	add.s32 	%r3509, %r3508, -1013796935;
	shf.l.wrap.b32 	%r3510, %r3509, %r3509, 15;
	add.s32 	%r3557, %r3510, %r3558;
	// begin inline asm
	lop3.b32 %r3305, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r3511, %r3305, %r3304;
	add.s32 	%r3512, %r3511, -343485551;
	shf.l.wrap.b32 	%r3513, %r3512, %r3512, 21;
	add.s32 	%r3556, %r3557, %r3513;
	add.s32 	%r2, %r2, -1;
	setp.ne.s32 	%p20, %r2, 0;
	@%p20 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_25;

$L__BB0_9:
	setp.eq.s32 	%p11, %r3522, 8;
	@%p11 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_10;

$L__BB0_21:
	add.s32 	%r156, %r780, -176418897;
	add.s32 	%r157, %r781, 1200080426;
	add.s32 	%r158, %r15, -1502002290;
	add.s32 	%r159, %r781, -701558691;
	add.s32 	%r160, %r780, -405537848;
	add.s32 	%r161, %r15, -1019803690;
	add.s32 	%r162, %r781, -378558;
	add.s32 	%r163, %r15, -35309556;
	add.s32 	%r164, %r780, 1272893353;
	add.s32 	%r165, %r15, -1416354905;
	add.s32 	%r166, %r781, -57434055;
	add.s32 	%r167, %r780, -145523070;

$L__BB0_22:
	add.s32 	%r2856, %r3555, 1051707256;
	shf.l.wrap.b32 	%r2857, %r2856, %r2856, 7;
	add.s32 	%r2615, %r2857, -271733879;
	mov.u32 	%r2611, -271733879;
	and.b32  	%r2858, %r2615, 2004318071;
	xor.b32  	%r2859, %r2858, -1732584194;
	add.s32 	%r2860, %r3556, %r2859;
	add.s32 	%r2861, %r2860, -389564587;
	shf.l.wrap.b32 	%r2862, %r2861, %r2861, 12;
	add.s32 	%r2619, %r2862, %r2615;
	// begin inline asm
	lop3.b32 %r2608, %r2619, %r2615, %r2611, 202;
	// end inline asm
	add.s32 	%r2863, %r3557, %r2608;
	add.s32 	%r2864, %r2863, 1435904727;
	shf.l.wrap.b32 	%r2865, %r2864, %r2864, 17;
	add.s32 	%r2623, %r2619, %r2865;
	// begin inline asm
	lop3.b32 %r2612, %r2623, %r2619, %r2615, 202;
	// end inline asm
	add.s32 	%r2866, %r3558, %r2612;
	add.s32 	%r2867, %r2866, -1044525331;
	shf.l.wrap.b32 	%r2868, %r2867, %r2867, 22;
	add.s32 	%r2627, %r2623, %r2868;
	// begin inline asm
	lop3.b32 %r2616, %r2627, %r2623, %r2619, 202;
	// end inline asm
	add.s32 	%r2869, %r156, %r2615;
	add.s32 	%r2870, %r2869, %r2616;
	shf.l.wrap.b32 	%r2871, %r2870, %r2870, 7;
	add.s32 	%r2631, %r2627, %r2871;
	// begin inline asm
	lop3.b32 %r2620, %r2631, %r2627, %r2623, 202;
	// end inline asm
	add.s32 	%r2872, %r157, %r2620;
	add.s32 	%r2873, %r2872, %r2619;
	shf.l.wrap.b32 	%r2874, %r2873, %r2873, 12;
	add.s32 	%r2635, %r2874, %r2631;
	// begin inline asm
	lop3.b32 %r2624, %r2635, %r2631, %r2627, 202;
	// end inline asm
	add.s32 	%r2875, %r2624, %r2623;
	add.s32 	%r2876, %r2875, -1473231213;
	shf.l.wrap.b32 	%r2877, %r2876, %r2876, 17;
	add.s32 	%r2639, %r2635, %r2877;
	// begin inline asm
	lop3.b32 %r2628, %r2639, %r2635, %r2631, 202;
	// end inline asm
	add.s32 	%r2878, %r2628, %r2627;
	add.s32 	%r2879, %r2878, -45705983;
	shf.l.wrap.b32 	%r2880, %r2879, %r2879, 22;
	add.s32 	%r2643, %r2639, %r2880;
	// begin inline asm
	lop3.b32 %r2632, %r2643, %r2639, %r2635, 202;
	// end inline asm
	add.s32 	%r2881, %r2632, %r2631;
	add.s32 	%r2882, %r2881, 1770035416;
	shf.l.wrap.b32 	%r2883, %r2882, %r2882, 7;
	add.s32 	%r2647, %r2643, %r2883;
	// begin inline asm
	lop3.b32 %r2636, %r2647, %r2643, %r2639, 202;
	// end inline asm
	add.s32 	%r2884, %r2636, %r2635;
	add.s32 	%r2885, %r2884, -1958414417;
	shf.l.wrap.b32 	%r2886, %r2885, %r2885, 12;
	add.s32 	%r2651, %r2886, %r2647;
	// begin inline asm
	lop3.b32 %r2640, %r2651, %r2647, %r2643, 202;
	// end inline asm
	add.s32 	%r2887, %r2640, %r2639;
	add.s32 	%r2888, %r2887, -42063;
	shf.l.wrap.b32 	%r2889, %r2888, %r2888, 17;
	add.s32 	%r2655, %r2889, %r2651;
	// begin inline asm
	lop3.b32 %r2644, %r2655, %r2651, %r2647, 202;
	// end inline asm
	add.s32 	%r2890, %r2644, %r2643;
	add.s32 	%r2891, %r2890, -1990404162;
	shf.l.wrap.b32 	%r2892, %r2891, %r2891, 22;
	add.s32 	%r2659, %r2892, %r2655;
	// begin inline asm
	lop3.b32 %r2648, %r2659, %r2655, %r2651, 202;
	// end inline asm
	add.s32 	%r2893, %r2648, %r2647;
	add.s32 	%r2894, %r2893, 1804603682;
	shf.l.wrap.b32 	%r2895, %r2894, %r2894, 7;
	add.s32 	%r2663, %r2895, %r2659;
	// begin inline asm
	lop3.b32 %r2652, %r2663, %r2659, %r2655, 202;
	// end inline asm
	add.s32 	%r2896, %r2652, %r2651;
	add.s32 	%r2897, %r2896, -40341101;
	shf.l.wrap.b32 	%r2898, %r2897, %r2897, 12;
	add.s32 	%r2667, %r2898, %r2663;
	// begin inline asm
	lop3.b32 %r2656, %r2667, %r2663, %r2659, 202;
	// end inline asm
	add.s32 	%r2899, %r158, %r2656;
	add.s32 	%r2900, %r2899, %r2655;
	shf.l.wrap.b32 	%r2901, %r2900, %r2900, 17;
	add.s32 	%r2671, %r2901, %r2667;
	// begin inline asm
	lop3.b32 %r2660, %r2671, %r2667, %r2663, 202;
	// end inline asm
	add.s32 	%r2902, %r2660, %r2659;
	add.s32 	%r2903, %r2902, 1236535329;
	shf.l.wrap.b32 	%r2904, %r2903, %r2903, 22;
	add.s32 	%r2675, %r2671, %r2904;
	// begin inline asm
	lop3.b32 %r2664, %r2675, %r2671, %r2667, 228;
	// end inline asm
	add.s32 	%r2905, %r3556, %r2664;
	add.s32 	%r2906, %r2905, %r2663;
	add.s32 	%r2907, %r2906, -437530389;
	shf.l.wrap.b32 	%r2908, %r2907, %r2907, 5;
	add.s32 	%r2679, %r2908, %r2675;
	// begin inline asm
	lop3.b32 %r2668, %r2679, %r2675, %r2671, 228;
	// end inline asm
	add.s32 	%r2909, %r2668, %r2667;
	add.s32 	%r2910, %r2909, -1069501504;
	shf.l.wrap.b32 	%r2911, %r2910, %r2910, 9;
	add.s32 	%r2683, %r2679, %r2911;
	// begin inline asm
	lop3.b32 %r2672, %r2683, %r2679, %r2675, 228;
	// end inline asm
	add.s32 	%r2912, %r2672, %r2671;
	add.s32 	%r2913, %r2912, 643717713;
	shf.l.wrap.b32 	%r2914, %r2913, %r2913, 14;
	add.s32 	%r2687, %r2914, %r2683;
	// begin inline asm
	lop3.b32 %r2676, %r2687, %r2683, %r2679, 228;
	// end inline asm
	add.s32 	%r2915, %r3555, %r2676;
	add.s32 	%r2916, %r2915, %r2675;
	add.s32 	%r2917, %r2916, 1358686891;
	shf.l.wrap.b32 	%r2918, %r2917, %r2917, 20;
	add.s32 	%r2691, %r2918, %r2687;
	// begin inline asm
	lop3.b32 %r2680, %r2691, %r2687, %r2683, 228;
	// end inline asm
	add.s32 	%r2919, %r159, %r2680;
	add.s32 	%r2920, %r2919, %r2679;
	shf.l.wrap.b32 	%r2921, %r2920, %r2920, 5;
	add.s32 	%r2695, %r2921, %r2691;
	// begin inline asm
	lop3.b32 %r2684, %r2695, %r2691, %r2687, 228;
	// end inline asm
	add.s32 	%r2922, %r2684, %r2683;
	add.s32 	%r2923, %r2922, 38016083;
	shf.l.wrap.b32 	%r2924, %r2923, %r2923, 9;
	add.s32 	%r2699, %r2695, %r2924;
	// begin inline asm
	lop3.b32 %r2688, %r2699, %r2695, %r2691, 228;
	// end inline asm
	add.s32 	%r2925, %r2688, %r2687;
	add.s32 	%r2926, %r2925, -660478335;
	shf.l.wrap.b32 	%r2927, %r2926, %r2926, 14;
	add.s32 	%r2703, %r2699, %r2927;
	// begin inline asm
	lop3.b32 %r2692, %r2703, %r2699, %r2695, 228;
	// end inline asm
	add.s32 	%r2928, %r160, %r2692;
	add.s32 	%r2929, %r2928, %r2691;
	shf.l.wrap.b32 	%r2930, %r2929, %r2929, 20;
	add.s32 	%r2707, %r2930, %r2703;
	// begin inline asm
	lop3.b32 %r2696, %r2707, %r2703, %r2699, 228;
	// end inline asm
	add.s32 	%r2931, %r2696, %r2695;
	add.s32 	%r2932, %r2931, 568446438;
	shf.l.wrap.b32 	%r2933, %r2932, %r2932, 5;
	add.s32 	%r2711, %r2707, %r2933;
	// begin inline asm
	lop3.b32 %r2700, %r2711, %r2707, %r2703, 228;
	// end inline asm
	add.s32 	%r2934, %r161, %r2700;
	add.s32 	%r2935, %r2934, %r2699;
	shf.l.wrap.b32 	%r2936, %r2935, %r2935, 9;
	add.s32 	%r2715, %r2936, %r2711;
	// begin inline asm
	lop3.b32 %r2704, %r2715, %r2711, %r2707, 228;
	// end inline asm
	add.s32 	%r2937, %r3558, %r2704;
	add.s32 	%r2938, %r2937, %r2703;
	add.s32 	%r2939, %r2938, 84369917;
	shf.l.wrap.b32 	%r2940, %r2939, %r2939, 14;
	add.s32 	%r2719, %r2940, %r2715;
	// begin inline asm
	lop3.b32 %r2708, %r2719, %r2715, %r2711, 228;
	// end inline asm
	add.s32 	%r2941, %r2708, %r2707;
	add.s32 	%r2942, %r2941, 1163531501;
	shf.l.wrap.b32 	%r2943, %r2942, %r2942, 20;
	add.s32 	%r2723, %r2943, %r2719;
	// begin inline asm
	lop3.b32 %r2712, %r2723, %r2719, %r2715, 228;
	// end inline asm
	add.s32 	%r2944, %r2712, %r2711;
	add.s32 	%r2945, %r2944, -1444681467;
	shf.l.wrap.b32 	%r2946, %r2945, %r2945, 5;
	add.s32 	%r2727, %r2946, %r2723;
	// begin inline asm
	lop3.b32 %r2716, %r2727, %r2723, %r2719, 228;
	// end inline asm
	add.s32 	%r2947, %r3557, %r2716;
	add.s32 	%r2948, %r2947, %r2715;
	add.s32 	%r2949, %r2948, -1783987978;
	shf.l.wrap.b32 	%r2950, %r2949, %r2949, 9;
	add.s32 	%r2731, %r2950, %r2727;
	// begin inline asm
	lop3.b32 %r2720, %r2731, %r2727, %r2723, 228;
	// end inline asm
	add.s32 	%r2951, %r2720, %r2719;
	add.s32 	%r2952, %r2951, 1735328473;
	shf.l.wrap.b32 	%r2953, %r2952, %r2952, 14;
	add.s32 	%r2735, %r2731, %r2953;
	// begin inline asm
	lop3.b32 %r2724, %r2735, %r2731, %r2727, 228;
	// end inline asm
	add.s32 	%r2954, %r2724, %r2723;
	add.s32 	%r2955, %r2954, -1926607734;
	shf.l.wrap.b32 	%r2956, %r2955, %r2955, 20;
	add.s32 	%r2739, %r2735, %r2956;
	// begin inline asm
	lop3.b32 %r2728, %r2739, %r2735, %r2731, 150;
	// end inline asm
	add.s32 	%r2957, %r162, %r2728;
	add.s32 	%r2958, %r2957, %r2727;
	shf.l.wrap.b32 	%r2959, %r2958, %r2958, 4;
	add.s32 	%r2743, %r2959, %r2739;
	// begin inline asm
	lop3.b32 %r2732, %r2743, %r2739, %r2735, 150;
	// end inline asm
	add.s32 	%r2960, %r2732, %r2731;
	add.s32 	%r2961, %r2960, -2022574463;
	shf.l.wrap.b32 	%r2962, %r2961, %r2961, 11;
	add.s32 	%r2747, %r2962, %r2743;
	// begin inline asm
	lop3.b32 %r2736, %r2747, %r2743, %r2739, 150;
	// end inline asm
	add.s32 	%r2963, %r2736, %r2735;
	add.s32 	%r2964, %r2963, 1839030562;
	shf.l.wrap.b32 	%r2965, %r2964, %r2964, 16;
	add.s32 	%r2751, %r2965, %r2747;
	// begin inline asm
	lop3.b32 %r2740, %r2751, %r2747, %r2743, 150;
	// end inline asm
	add.s32 	%r2966, %r163, %r2740;
	add.s32 	%r2967, %r2966, %r2739;
	shf.l.wrap.b32 	%r2968, %r2967, %r2967, 23;
	add.s32 	%r2755, %r2968, %r2751;
	// begin inline asm
	lop3.b32 %r2744, %r2755, %r2751, %r2747, 150;
	// end inline asm
	add.s32 	%r2969, %r3556, %r2744;
	add.s32 	%r2970, %r2969, %r2743;
	add.s32 	%r2971, %r2970, -1802725939;
	shf.l.wrap.b32 	%r2972, %r2971, %r2971, 4;
	add.s32 	%r2759, %r2972, %r2755;
	// begin inline asm
	lop3.b32 %r2748, %r2759, %r2755, %r2751, 150;
	// end inline asm
	add.s32 	%r2973, %r164, %r2748;
	add.s32 	%r2974, %r2973, %r2747;
	shf.l.wrap.b32 	%r2975, %r2974, %r2974, 11;
	add.s32 	%r2763, %r2975, %r2759;
	// begin inline asm
	lop3.b32 %r2752, %r2763, %r2759, %r2755, 150;
	// end inline asm
	add.s32 	%r2976, %r2752, %r2751;
	add.s32 	%r2977, %r2976, -155497632;
	shf.l.wrap.b32 	%r2978, %r2977, %r2977, 16;
	add.s32 	%r2767, %r2763, %r2978;
	// begin inline asm
	lop3.b32 %r2756, %r2767, %r2763, %r2759, 150;
	// end inline asm
	add.s32 	%r2979, %r2756, %r2755;
	add.s32 	%r2980, %r2979, -1094730640;
	shf.l.wrap.b32 	%r2981, %r2980, %r2980, 23;
	add.s32 	%r2771, %r2981, %r2767;
	// begin inline asm
	lop3.b32 %r2760, %r2771, %r2767, %r2763, 150;
	// end inline asm
	add.s32 	%r2982, %r2760, %r2759;
	add.s32 	%r2983, %r2982, 681279174;
	shf.l.wrap.b32 	%r2984, %r2983, %r2983, 4;
	add.s32 	%r2775, %r2984, %r2771;
	// begin inline asm
	lop3.b32 %r2764, %r2775, %r2771, %r2767, 150;
	// end inline asm
	add.s32 	%r2985, %r3555, %r2764;
	add.s32 	%r2986, %r2985, %r2763;
	add.s32 	%r2987, %r2986, 1374046971;
	shf.l.wrap.b32 	%r2988, %r2987, %r2987, 11;
	add.s32 	%r2779, %r2988, %r2775;
	// begin inline asm
	lop3.b32 %r2768, %r2779, %r2775, %r2771, 150;
	// end inline asm
	add.s32 	%r2989, %r3558, %r2768;
	add.s32 	%r2990, %r2989, %r2767;
	add.s32 	%r2991, %r2990, -450788101;
	shf.l.wrap.b32 	%r2992, %r2991, %r2991, 16;
	add.s32 	%r2783, %r2992, %r2779;
	// begin inline asm
	lop3.b32 %r2772, %r2783, %r2779, %r2775, 150;
	// end inline asm
	add.s32 	%r2993, %r2772, %r2771;
	add.s32 	%r2994, %r2993, 76029317;
	shf.l.wrap.b32 	%r2995, %r2994, %r2994, 23;
	add.s32 	%r2787, %r2783, %r2995;
	// begin inline asm
	lop3.b32 %r2776, %r2787, %r2783, %r2779, 150;
	// end inline asm
	add.s32 	%r2996, %r2776, %r2775;
	add.s32 	%r2997, %r2996, -640364487;
	shf.l.wrap.b32 	%r2998, %r2997, %r2997, 4;
	add.s32 	%r2791, %r2787, %r2998;
	// begin inline asm
	lop3.b32 %r2780, %r2791, %r2787, %r2783, 150;
	// end inline asm
	add.s32 	%r2999, %r2780, %r2779;
	add.s32 	%r3000, %r2999, -421815835;
	shf.l.wrap.b32 	%r3001, %r3000, %r3000, 11;
	add.s32 	%r2795, %r3001, %r2791;
	// begin inline asm
	lop3.b32 %r2784, %r2795, %r2791, %r2787, 150;
	// end inline asm
	add.s32 	%r3002, %r2784, %r2783;
	add.s32 	%r3003, %r3002, 530742520;
	shf.l.wrap.b32 	%r3004, %r3003, %r3003, 16;
	add.s32 	%r2799, %r3004, %r2795;
	// begin inline asm
	lop3.b32 %r2788, %r2799, %r2795, %r2791, 150;
	// end inline asm
	add.s32 	%r3005, %r3557, %r2788;
	add.s32 	%r3006, %r3005, %r2787;
	add.s32 	%r3007, %r3006, 1567044451;
	shf.l.wrap.b32 	%r3008, %r3007, %r3007, 23;
	add.s32 	%r2803, %r3008, %r2799;
	// begin inline asm
	lop3.b32 %r2792, %r2803, %r2799, %r2795, 57;
	// end inline asm
	add.s32 	%r3009, %r3555, %r2792;
	add.s32 	%r3010, %r3009, %r2791;
	add.s32 	%r3011, %r3010, 1533953349;
	shf.l.wrap.b32 	%r3012, %r3011, %r3011, 6;
	add.s32 	%r2807, %r3012, %r2803;
	// begin inline asm
	lop3.b32 %r2796, %r2807, %r2803, %r2799, 57;
	// end inline asm
	add.s32 	%r3013, %r2796, %r2795;
	add.s32 	%r3014, %r3013, 1126891415;
	shf.l.wrap.b32 	%r3015, %r3014, %r3014, 10;
	add.s32 	%r2811, %r2807, %r3015;
	// begin inline asm
	lop3.b32 %r2800, %r2811, %r2807, %r2803, 57;
	// end inline asm
	add.s32 	%r3016, %r165, %r2800;
	add.s32 	%r3017, %r3016, %r2799;
	shf.l.wrap.b32 	%r3018, %r3017, %r3017, 15;
	add.s32 	%r2815, %r3018, %r2811;
	// begin inline asm
	lop3.b32 %r2804, %r2815, %r2811, %r2807, 57;
	// end inline asm
	add.s32 	%r3019, %r166, %r2804;
	add.s32 	%r3020, %r3019, %r2803;
	shf.l.wrap.b32 	%r3021, %r3020, %r3020, 21;
	add.s32 	%r2819, %r3021, %r2815;
	// begin inline asm
	lop3.b32 %r2808, %r2819, %r2815, %r2811, 57;
	// end inline asm
	add.s32 	%r3022, %r2808, %r2807;
	add.s32 	%r3023, %r3022, 1700485571;
	shf.l.wrap.b32 	%r3024, %r3023, %r3023, 6;
	add.s32 	%r2823, %r2819, %r3024;
	// begin inline asm
	lop3.b32 %r2812, %r2823, %r2819, %r2815, 57;
	// end inline asm
	add.s32 	%r3025, %r3558, %r2812;
	add.s32 	%r3026, %r3025, %r2811;
	add.s32 	%r3027, %r3026, -1623252728;
	shf.l.wrap.b32 	%r3028, %r3027, %r3027, 10;
	add.s32 	%r2827, %r3028, %r2823;
	// begin inline asm
	lop3.b32 %r2816, %r2827, %r2823, %r2819, 57;
	// end inline asm
	add.s32 	%r3029, %r2816, %r2815;
	add.s32 	%r3030, %r3029, -1051523;
	shf.l.wrap.b32 	%r3031, %r3030, %r3030, 15;
	add.s32 	%r2831, %r2827, %r3031;
	// begin inline asm
	lop3.b32 %r2820, %r2831, %r2827, %r2823, 57;
	// end inline asm
	add.s32 	%r3032, %r3556, %r2820;
	add.s32 	%r3033, %r3032, %r2819;
	add.s32 	%r3034, %r3033, 1968310618;
	shf.l.wrap.b32 	%r3035, %r3034, %r3034, 21;
	add.s32 	%r2835, %r3035, %r2831;
	// begin inline asm
	lop3.b32 %r2824, %r2835, %r2831, %r2827, 57;
	// end inline asm
	add.s32 	%r3036, %r2824, %r2823;
	add.s32 	%r3037, %r3036, 1873313359;
	shf.l.wrap.b32 	%r3038, %r3037, %r3037, 6;
	add.s32 	%r2839, %r2835, %r3038;
	// begin inline asm
	lop3.b32 %r2828, %r2839, %r2835, %r2831, 57;
	// end inline asm
	add.s32 	%r3039, %r2828, %r2827;
	add.s32 	%r3040, %r3039, -30611744;
	shf.l.wrap.b32 	%r3041, %r3040, %r3040, 10;
	add.s32 	%r2843, %r2839, %r3041;
	// begin inline asm
	lop3.b32 %r2832, %r2843, %r2839, %r2835, 57;
	// end inline asm
	add.s32 	%r3042, %r2832, %r2831;
	add.s32 	%r3043, %r3042, -1560198252;
	shf.l.wrap.b32 	%r3044, %r3043, %r3043, 15;
	add.s32 	%r2847, %r2843, %r3044;
	// begin inline asm
	lop3.b32 %r2836, %r2847, %r2843, %r2839, 57;
	// end inline asm
	add.s32 	%r3045, %r2836, %r2835;
	add.s32 	%r3046, %r3045, 1309151649;
	shf.l.wrap.b32 	%r3047, %r3046, %r3046, 21;
	add.s32 	%r2851, %r3047, %r2847;
	// begin inline asm
	lop3.b32 %r2840, %r2851, %r2847, %r2843, 57;
	// end inline asm
	add.s32 	%r3048, %r167, %r2840;
	add.s32 	%r3049, %r3048, %r2839;
	shf.l.wrap.b32 	%r3050, %r3049, %r3049, 6;
	add.s32 	%r3555, %r3050, %r2851;
	// begin inline asm
	lop3.b32 %r2844, %r3555, %r2851, %r2847, 57;
	// end inline asm
	add.s32 	%r3051, %r2844, %r2843;
	add.s32 	%r3052, %r3051, -1120210379;
	shf.l.wrap.b32 	%r3053, %r3052, %r3052, 10;
	add.s32 	%r3558, %r3555, %r3053;
	// begin inline asm
	lop3.b32 %r2848, %r3558, %r3555, %r2851, 57;
	// end inline asm
	add.s32 	%r3054, %r3557, %r2848;
	add.s32 	%r3055, %r3054, %r2847;
	add.s32 	%r3056, %r3055, -1013796935;
	shf.l.wrap.b32 	%r3057, %r3056, %r3056, 15;
	add.s32 	%r3557, %r3057, %r3558;
	// begin inline asm
	lop3.b32 %r2852, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r3058, %r2852, %r2851;
	add.s32 	%r3059, %r3058, -343485551;
	shf.l.wrap.b32 	%r3060, %r3059, %r3059, 21;
	add.s32 	%r3556, %r3557, %r3060;
	add.s32 	%r2, %r2, -1;
	setp.eq.s32 	%p19, %r2, 0;
	@%p19 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_22;

$L__BB0_10:
	setp.lt.u32 	%p12, %r3521, 12;
	@%p12 bra 	$L__BB0_19;
	bra.uni 	$L__BB0_11;

$L__BB0_19:
	add.s32 	%r130, %r780, -176418897;
	add.s32 	%r131, %r781, 1200080426;
	add.s32 	%r132, %r782, -1473231341;
	add.s32 	%r133, %r15, -1502002290;
	add.s32 	%r134, %r782, -1069501632;
	add.s32 	%r135, %r781, -701558691;
	add.s32 	%r136, %r780, -405537848;
	add.s32 	%r137, %r15, -1019803690;
	add.s32 	%r138, %r781, -378558;
	add.s32 	%r139, %r15, -35309556;
	add.s32 	%r140, %r780, 1272893353;
	add.s32 	%r141, %r782, 76029189;
	add.s32 	%r142, %r15, -1416354905;
	add.s32 	%r143, %r781, -57434055;
	add.s32 	%r144, %r782, -1560198380;
	add.s32 	%r145, %r780, -145523070;

$L__BB0_20:
	add.s32 	%r2403, %r3555, 1051707256;
	shf.l.wrap.b32 	%r2404, %r2403, %r2403, 7;
	add.s32 	%r2162, %r2404, -271733879;
	mov.u32 	%r2158, -271733879;
	and.b32  	%r2405, %r2162, 2004318071;
	xor.b32  	%r2406, %r2405, -1732584194;
	add.s32 	%r2407, %r3556, %r2406;
	add.s32 	%r2408, %r2407, -389564587;
	shf.l.wrap.b32 	%r2409, %r2408, %r2408, 12;
	add.s32 	%r2166, %r2409, %r2162;
	// begin inline asm
	lop3.b32 %r2155, %r2166, %r2162, %r2158, 202;
	// end inline asm
	add.s32 	%r2410, %r3557, %r2155;
	add.s32 	%r2411, %r2410, 1435904727;
	shf.l.wrap.b32 	%r2412, %r2411, %r2411, 17;
	add.s32 	%r2170, %r2166, %r2412;
	// begin inline asm
	lop3.b32 %r2159, %r2170, %r2166, %r2162, 202;
	// end inline asm
	add.s32 	%r2413, %r3558, %r2159;
	add.s32 	%r2414, %r2413, -1044525331;
	shf.l.wrap.b32 	%r2415, %r2414, %r2414, 22;
	add.s32 	%r2174, %r2170, %r2415;
	// begin inline asm
	lop3.b32 %r2163, %r2174, %r2170, %r2166, 202;
	// end inline asm
	add.s32 	%r2416, %r130, %r2162;
	add.s32 	%r2417, %r2416, %r2163;
	shf.l.wrap.b32 	%r2418, %r2417, %r2417, 7;
	add.s32 	%r2178, %r2174, %r2418;
	// begin inline asm
	lop3.b32 %r2167, %r2178, %r2174, %r2170, 202;
	// end inline asm
	add.s32 	%r2419, %r131, %r2167;
	add.s32 	%r2420, %r2419, %r2166;
	shf.l.wrap.b32 	%r2421, %r2420, %r2420, 12;
	add.s32 	%r2182, %r2421, %r2178;
	// begin inline asm
	lop3.b32 %r2171, %r2182, %r2178, %r2174, 202;
	// end inline asm
	add.s32 	%r2422, %r132, %r2171;
	add.s32 	%r2423, %r2422, %r2170;
	shf.l.wrap.b32 	%r2424, %r2423, %r2423, 17;
	add.s32 	%r2186, %r2424, %r2182;
	// begin inline asm
	lop3.b32 %r2175, %r2186, %r2182, %r2178, 202;
	// end inline asm
	add.s32 	%r2425, %r2175, %r2174;
	add.s32 	%r2426, %r2425, -45705983;
	shf.l.wrap.b32 	%r2427, %r2426, %r2426, 22;
	add.s32 	%r2190, %r2186, %r2427;
	// begin inline asm
	lop3.b32 %r2179, %r2190, %r2186, %r2182, 202;
	// end inline asm
	add.s32 	%r2428, %r2179, %r2178;
	add.s32 	%r2429, %r2428, 1770035416;
	shf.l.wrap.b32 	%r2430, %r2429, %r2429, 7;
	add.s32 	%r2194, %r2190, %r2430;
	// begin inline asm
	lop3.b32 %r2183, %r2194, %r2190, %r2186, 202;
	// end inline asm
	add.s32 	%r2431, %r2183, %r2182;
	add.s32 	%r2432, %r2431, -1958414417;
	shf.l.wrap.b32 	%r2433, %r2432, %r2432, 12;
	add.s32 	%r2198, %r2433, %r2194;
	// begin inline asm
	lop3.b32 %r2187, %r2198, %r2194, %r2190, 202;
	// end inline asm
	add.s32 	%r2434, %r2187, %r2186;
	add.s32 	%r2435, %r2434, -42063;
	shf.l.wrap.b32 	%r2436, %r2435, %r2435, 17;
	add.s32 	%r2202, %r2436, %r2198;
	// begin inline asm
	lop3.b32 %r2191, %r2202, %r2198, %r2194, 202;
	// end inline asm
	add.s32 	%r2437, %r2191, %r2190;
	add.s32 	%r2438, %r2437, -1990404162;
	shf.l.wrap.b32 	%r2439, %r2438, %r2438, 22;
	add.s32 	%r2206, %r2439, %r2202;
	// begin inline asm
	lop3.b32 %r2195, %r2206, %r2202, %r2198, 202;
	// end inline asm
	add.s32 	%r2440, %r2195, %r2194;
	add.s32 	%r2441, %r2440, 1804603682;
	shf.l.wrap.b32 	%r2442, %r2441, %r2441, 7;
	add.s32 	%r2210, %r2442, %r2206;
	// begin inline asm
	lop3.b32 %r2199, %r2210, %r2206, %r2202, 202;
	// end inline asm
	add.s32 	%r2443, %r2199, %r2198;
	add.s32 	%r2444, %r2443, -40341101;
	shf.l.wrap.b32 	%r2445, %r2444, %r2444, 12;
	add.s32 	%r2214, %r2445, %r2210;
	// begin inline asm
	lop3.b32 %r2203, %r2214, %r2210, %r2206, 202;
	// end inline asm
	add.s32 	%r2446, %r133, %r2203;
	add.s32 	%r2447, %r2446, %r2202;
	shf.l.wrap.b32 	%r2448, %r2447, %r2447, 17;
	add.s32 	%r2218, %r2448, %r2214;
	// begin inline asm
	lop3.b32 %r2207, %r2218, %r2214, %r2210, 202;
	// end inline asm
	add.s32 	%r2449, %r2207, %r2206;
	add.s32 	%r2450, %r2449, 1236535329;
	shf.l.wrap.b32 	%r2451, %r2450, %r2450, 22;
	add.s32 	%r2222, %r2218, %r2451;
	// begin inline asm
	lop3.b32 %r2211, %r2222, %r2218, %r2214, 228;
	// end inline asm
	add.s32 	%r2452, %r3556, %r2211;
	add.s32 	%r2453, %r2452, %r2210;
	add.s32 	%r2454, %r2453, -437530389;
	shf.l.wrap.b32 	%r2455, %r2454, %r2454, 5;
	add.s32 	%r2226, %r2455, %r2222;
	// begin inline asm
	lop3.b32 %r2215, %r2226, %r2222, %r2218, 228;
	// end inline asm
	add.s32 	%r2456, %r134, %r2215;
	add.s32 	%r2457, %r2456, %r2214;
	shf.l.wrap.b32 	%r2458, %r2457, %r2457, 9;
	add.s32 	%r2230, %r2458, %r2226;
	// begin inline asm
	lop3.b32 %r2219, %r2230, %r2226, %r2222, 228;
	// end inline asm
	add.s32 	%r2459, %r2219, %r2218;
	add.s32 	%r2460, %r2459, 643717713;
	shf.l.wrap.b32 	%r2461, %r2460, %r2460, 14;
	add.s32 	%r2234, %r2461, %r2230;
	// begin inline asm
	lop3.b32 %r2223, %r2234, %r2230, %r2226, 228;
	// end inline asm
	add.s32 	%r2462, %r3555, %r2223;
	add.s32 	%r2463, %r2462, %r2222;
	add.s32 	%r2464, %r2463, 1358686891;
	shf.l.wrap.b32 	%r2465, %r2464, %r2464, 20;
	add.s32 	%r2238, %r2465, %r2234;
	// begin inline asm
	lop3.b32 %r2227, %r2238, %r2234, %r2230, 228;
	// end inline asm
	add.s32 	%r2466, %r135, %r2227;
	add.s32 	%r2467, %r2466, %r2226;
	shf.l.wrap.b32 	%r2468, %r2467, %r2467, 5;
	add.s32 	%r2242, %r2468, %r2238;
	// begin inline asm
	lop3.b32 %r2231, %r2242, %r2238, %r2234, 228;
	// end inline asm
	add.s32 	%r2469, %r2231, %r2230;
	add.s32 	%r2470, %r2469, 38016083;
	shf.l.wrap.b32 	%r2471, %r2470, %r2470, 9;
	add.s32 	%r2246, %r2242, %r2471;
	// begin inline asm
	lop3.b32 %r2235, %r2246, %r2242, %r2238, 228;
	// end inline asm
	add.s32 	%r2472, %r2235, %r2234;
	add.s32 	%r2473, %r2472, -660478335;
	shf.l.wrap.b32 	%r2474, %r2473, %r2473, 14;
	add.s32 	%r2250, %r2246, %r2474;
	// begin inline asm
	lop3.b32 %r2239, %r2250, %r2246, %r2242, 228;
	// end inline asm
	add.s32 	%r2475, %r136, %r2239;
	add.s32 	%r2476, %r2475, %r2238;
	shf.l.wrap.b32 	%r2477, %r2476, %r2476, 20;
	add.s32 	%r2254, %r2477, %r2250;
	// begin inline asm
	lop3.b32 %r2243, %r2254, %r2250, %r2246, 228;
	// end inline asm
	add.s32 	%r2478, %r2243, %r2242;
	add.s32 	%r2479, %r2478, 568446438;
	shf.l.wrap.b32 	%r2480, %r2479, %r2479, 5;
	add.s32 	%r2258, %r2254, %r2480;
	// begin inline asm
	lop3.b32 %r2247, %r2258, %r2254, %r2250, 228;
	// end inline asm
	add.s32 	%r2481, %r137, %r2247;
	add.s32 	%r2482, %r2481, %r2246;
	shf.l.wrap.b32 	%r2483, %r2482, %r2482, 9;
	add.s32 	%r2262, %r2483, %r2258;
	// begin inline asm
	lop3.b32 %r2251, %r2262, %r2258, %r2254, 228;
	// end inline asm
	add.s32 	%r2484, %r3558, %r2251;
	add.s32 	%r2485, %r2484, %r2250;
	add.s32 	%r2486, %r2485, 84369917;
	shf.l.wrap.b32 	%r2487, %r2486, %r2486, 14;
	add.s32 	%r2266, %r2487, %r2262;
	// begin inline asm
	lop3.b32 %r2255, %r2266, %r2262, %r2258, 228;
	// end inline asm
	add.s32 	%r2488, %r2255, %r2254;
	add.s32 	%r2489, %r2488, 1163531501;
	shf.l.wrap.b32 	%r2490, %r2489, %r2489, 20;
	add.s32 	%r2270, %r2490, %r2266;
	// begin inline asm
	lop3.b32 %r2259, %r2270, %r2266, %r2262, 228;
	// end inline asm
	add.s32 	%r2491, %r2259, %r2258;
	add.s32 	%r2492, %r2491, -1444681467;
	shf.l.wrap.b32 	%r2493, %r2492, %r2492, 5;
	add.s32 	%r2274, %r2493, %r2270;
	// begin inline asm
	lop3.b32 %r2263, %r2274, %r2270, %r2266, 228;
	// end inline asm
	add.s32 	%r2494, %r3557, %r2263;
	add.s32 	%r2495, %r2494, %r2262;
	add.s32 	%r2496, %r2495, -1783987978;
	shf.l.wrap.b32 	%r2497, %r2496, %r2496, 9;
	add.s32 	%r2278, %r2497, %r2274;
	// begin inline asm
	lop3.b32 %r2267, %r2278, %r2274, %r2270, 228;
	// end inline asm
	add.s32 	%r2498, %r2267, %r2266;
	add.s32 	%r2499, %r2498, 1735328473;
	shf.l.wrap.b32 	%r2500, %r2499, %r2499, 14;
	add.s32 	%r2282, %r2278, %r2500;
	// begin inline asm
	lop3.b32 %r2271, %r2282, %r2278, %r2274, 228;
	// end inline asm
	add.s32 	%r2501, %r2271, %r2270;
	add.s32 	%r2502, %r2501, -1926607734;
	shf.l.wrap.b32 	%r2503, %r2502, %r2502, 20;
	add.s32 	%r2286, %r2282, %r2503;
	// begin inline asm
	lop3.b32 %r2275, %r2286, %r2282, %r2278, 150;
	// end inline asm
	add.s32 	%r2504, %r138, %r2275;
	add.s32 	%r2505, %r2504, %r2274;
	shf.l.wrap.b32 	%r2506, %r2505, %r2505, 4;
	add.s32 	%r2290, %r2506, %r2286;
	// begin inline asm
	lop3.b32 %r2279, %r2290, %r2286, %r2282, 150;
	// end inline asm
	add.s32 	%r2507, %r2279, %r2278;
	add.s32 	%r2508, %r2507, -2022574463;
	shf.l.wrap.b32 	%r2509, %r2508, %r2508, 11;
	add.s32 	%r2294, %r2509, %r2290;
	// begin inline asm
	lop3.b32 %r2283, %r2294, %r2290, %r2286, 150;
	// end inline asm
	add.s32 	%r2510, %r2283, %r2282;
	add.s32 	%r2511, %r2510, 1839030562;
	shf.l.wrap.b32 	%r2512, %r2511, %r2511, 16;
	add.s32 	%r2298, %r2512, %r2294;
	// begin inline asm
	lop3.b32 %r2287, %r2298, %r2294, %r2290, 150;
	// end inline asm
	add.s32 	%r2513, %r139, %r2287;
	add.s32 	%r2514, %r2513, %r2286;
	shf.l.wrap.b32 	%r2515, %r2514, %r2514, 23;
	add.s32 	%r2302, %r2515, %r2298;
	// begin inline asm
	lop3.b32 %r2291, %r2302, %r2298, %r2294, 150;
	// end inline asm
	add.s32 	%r2516, %r3556, %r2291;
	add.s32 	%r2517, %r2516, %r2290;
	add.s32 	%r2518, %r2517, -1802725939;
	shf.l.wrap.b32 	%r2519, %r2518, %r2518, 4;
	add.s32 	%r2306, %r2519, %r2302;
	// begin inline asm
	lop3.b32 %r2295, %r2306, %r2302, %r2298, 150;
	// end inline asm
	add.s32 	%r2520, %r140, %r2295;
	add.s32 	%r2521, %r2520, %r2294;
	shf.l.wrap.b32 	%r2522, %r2521, %r2521, 11;
	add.s32 	%r2310, %r2522, %r2306;
	// begin inline asm
	lop3.b32 %r2299, %r2310, %r2306, %r2302, 150;
	// end inline asm
	add.s32 	%r2523, %r2299, %r2298;
	add.s32 	%r2524, %r2523, -155497632;
	shf.l.wrap.b32 	%r2525, %r2524, %r2524, 16;
	add.s32 	%r2314, %r2310, %r2525;
	// begin inline asm
	lop3.b32 %r2303, %r2314, %r2310, %r2306, 150;
	// end inline asm
	add.s32 	%r2526, %r2303, %r2302;
	add.s32 	%r2527, %r2526, -1094730640;
	shf.l.wrap.b32 	%r2528, %r2527, %r2527, 23;
	add.s32 	%r2318, %r2528, %r2314;
	// begin inline asm
	lop3.b32 %r2307, %r2318, %r2314, %r2310, 150;
	// end inline asm
	add.s32 	%r2529, %r2307, %r2306;
	add.s32 	%r2530, %r2529, 681279174;
	shf.l.wrap.b32 	%r2531, %r2530, %r2530, 4;
	add.s32 	%r2322, %r2531, %r2318;
	// begin inline asm
	lop3.b32 %r2311, %r2322, %r2318, %r2314, 150;
	// end inline asm
	add.s32 	%r2532, %r3555, %r2311;
	add.s32 	%r2533, %r2532, %r2310;
	add.s32 	%r2534, %r2533, 1374046971;
	shf.l.wrap.b32 	%r2535, %r2534, %r2534, 11;
	add.s32 	%r2326, %r2535, %r2322;
	// begin inline asm
	lop3.b32 %r2315, %r2326, %r2322, %r2318, 150;
	// end inline asm
	add.s32 	%r2536, %r3558, %r2315;
	add.s32 	%r2537, %r2536, %r2314;
	add.s32 	%r2538, %r2537, -450788101;
	shf.l.wrap.b32 	%r2539, %r2538, %r2538, 16;
	add.s32 	%r2330, %r2539, %r2326;
	// begin inline asm
	lop3.b32 %r2319, %r2330, %r2326, %r2322, 150;
	// end inline asm
	add.s32 	%r2540, %r141, %r2319;
	add.s32 	%r2541, %r2540, %r2318;
	shf.l.wrap.b32 	%r2542, %r2541, %r2541, 23;
	add.s32 	%r2334, %r2542, %r2330;
	// begin inline asm
	lop3.b32 %r2323, %r2334, %r2330, %r2326, 150;
	// end inline asm
	add.s32 	%r2543, %r2323, %r2322;
	add.s32 	%r2544, %r2543, -640364487;
	shf.l.wrap.b32 	%r2545, %r2544, %r2544, 4;
	add.s32 	%r2338, %r2334, %r2545;
	// begin inline asm
	lop3.b32 %r2327, %r2338, %r2334, %r2330, 150;
	// end inline asm
	add.s32 	%r2546, %r2327, %r2326;
	add.s32 	%r2547, %r2546, -421815835;
	shf.l.wrap.b32 	%r2548, %r2547, %r2547, 11;
	add.s32 	%r2342, %r2548, %r2338;
	// begin inline asm
	lop3.b32 %r2331, %r2342, %r2338, %r2334, 150;
	// end inline asm
	add.s32 	%r2549, %r2331, %r2330;
	add.s32 	%r2550, %r2549, 530742520;
	shf.l.wrap.b32 	%r2551, %r2550, %r2550, 16;
	add.s32 	%r2346, %r2551, %r2342;
	// begin inline asm
	lop3.b32 %r2335, %r2346, %r2342, %r2338, 150;
	// end inline asm
	add.s32 	%r2552, %r3557, %r2335;
	add.s32 	%r2553, %r2552, %r2334;
	add.s32 	%r2554, %r2553, 1567044451;
	shf.l.wrap.b32 	%r2555, %r2554, %r2554, 23;
	add.s32 	%r2350, %r2555, %r2346;
	// begin inline asm
	lop3.b32 %r2339, %r2350, %r2346, %r2342, 57;
	// end inline asm
	add.s32 	%r2556, %r3555, %r2339;
	add.s32 	%r2557, %r2556, %r2338;
	add.s32 	%r2558, %r2557, 1533953349;
	shf.l.wrap.b32 	%r2559, %r2558, %r2558, 6;
	add.s32 	%r2354, %r2559, %r2350;
	// begin inline asm
	lop3.b32 %r2343, %r2354, %r2350, %r2346, 57;
	// end inline asm
	add.s32 	%r2560, %r2343, %r2342;
	add.s32 	%r2561, %r2560, 1126891415;
	shf.l.wrap.b32 	%r2562, %r2561, %r2561, 10;
	add.s32 	%r2358, %r2354, %r2562;
	// begin inline asm
	lop3.b32 %r2347, %r2358, %r2354, %r2350, 57;
	// end inline asm
	add.s32 	%r2563, %r142, %r2347;
	add.s32 	%r2564, %r2563, %r2346;
	shf.l.wrap.b32 	%r2565, %r2564, %r2564, 15;
	add.s32 	%r2362, %r2565, %r2358;
	// begin inline asm
	lop3.b32 %r2351, %r2362, %r2358, %r2354, 57;
	// end inline asm
	add.s32 	%r2566, %r143, %r2351;
	add.s32 	%r2567, %r2566, %r2350;
	shf.l.wrap.b32 	%r2568, %r2567, %r2567, 21;
	add.s32 	%r2366, %r2568, %r2362;
	// begin inline asm
	lop3.b32 %r2355, %r2366, %r2362, %r2358, 57;
	// end inline asm
	add.s32 	%r2569, %r2355, %r2354;
	add.s32 	%r2570, %r2569, 1700485571;
	shf.l.wrap.b32 	%r2571, %r2570, %r2570, 6;
	add.s32 	%r2370, %r2366, %r2571;
	// begin inline asm
	lop3.b32 %r2359, %r2370, %r2366, %r2362, 57;
	// end inline asm
	add.s32 	%r2572, %r3558, %r2359;
	add.s32 	%r2573, %r2572, %r2358;
	add.s32 	%r2574, %r2573, -1623252728;
	shf.l.wrap.b32 	%r2575, %r2574, %r2574, 10;
	add.s32 	%r2374, %r2575, %r2370;
	// begin inline asm
	lop3.b32 %r2363, %r2374, %r2370, %r2366, 57;
	// end inline asm
	add.s32 	%r2576, %r2363, %r2362;
	add.s32 	%r2577, %r2576, -1051523;
	shf.l.wrap.b32 	%r2578, %r2577, %r2577, 15;
	add.s32 	%r2378, %r2374, %r2578;
	// begin inline asm
	lop3.b32 %r2367, %r2378, %r2374, %r2370, 57;
	// end inline asm
	add.s32 	%r2579, %r3556, %r2367;
	add.s32 	%r2580, %r2579, %r2366;
	add.s32 	%r2581, %r2580, 1968310618;
	shf.l.wrap.b32 	%r2582, %r2581, %r2581, 21;
	add.s32 	%r2382, %r2582, %r2378;
	// begin inline asm
	lop3.b32 %r2371, %r2382, %r2378, %r2374, 57;
	// end inline asm
	add.s32 	%r2583, %r2371, %r2370;
	add.s32 	%r2584, %r2583, 1873313359;
	shf.l.wrap.b32 	%r2585, %r2584, %r2584, 6;
	add.s32 	%r2386, %r2382, %r2585;
	// begin inline asm
	lop3.b32 %r2375, %r2386, %r2382, %r2378, 57;
	// end inline asm
	add.s32 	%r2586, %r2375, %r2374;
	add.s32 	%r2587, %r2586, -30611744;
	shf.l.wrap.b32 	%r2588, %r2587, %r2587, 10;
	add.s32 	%r2390, %r2386, %r2588;
	// begin inline asm
	lop3.b32 %r2379, %r2390, %r2386, %r2382, 57;
	// end inline asm
	add.s32 	%r2589, %r144, %r2379;
	add.s32 	%r2590, %r2589, %r2378;
	shf.l.wrap.b32 	%r2591, %r2590, %r2590, 15;
	add.s32 	%r2394, %r2591, %r2390;
	// begin inline asm
	lop3.b32 %r2383, %r2394, %r2390, %r2386, 57;
	// end inline asm
	add.s32 	%r2592, %r2383, %r2382;
	add.s32 	%r2593, %r2592, 1309151649;
	shf.l.wrap.b32 	%r2594, %r2593, %r2593, 21;
	add.s32 	%r2398, %r2594, %r2394;
	// begin inline asm
	lop3.b32 %r2387, %r2398, %r2394, %r2390, 57;
	// end inline asm
	add.s32 	%r2595, %r145, %r2387;
	add.s32 	%r2596, %r2595, %r2386;
	shf.l.wrap.b32 	%r2597, %r2596, %r2596, 6;
	add.s32 	%r3555, %r2597, %r2398;
	// begin inline asm
	lop3.b32 %r2391, %r3555, %r2398, %r2394, 57;
	// end inline asm
	add.s32 	%r2598, %r2391, %r2390;
	add.s32 	%r2599, %r2598, -1120210379;
	shf.l.wrap.b32 	%r2600, %r2599, %r2599, 10;
	add.s32 	%r3558, %r3555, %r2600;
	// begin inline asm
	lop3.b32 %r2395, %r3558, %r3555, %r2398, 57;
	// end inline asm
	add.s32 	%r2601, %r3557, %r2395;
	add.s32 	%r2602, %r2601, %r2394;
	add.s32 	%r2603, %r2602, -1013796935;
	shf.l.wrap.b32 	%r2604, %r2603, %r2603, 15;
	add.s32 	%r3557, %r2604, %r3558;
	// begin inline asm
	lop3.b32 %r2399, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r2605, %r2399, %r2398;
	add.s32 	%r2606, %r2605, -343485551;
	shf.l.wrap.b32 	%r2607, %r2606, %r2606, 21;
	add.s32 	%r3556, %r3557, %r2607;
	add.s32 	%r2, %r2, -1;
	setp.eq.s32 	%p18, %r2, 0;
	@%p18 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_20;

$L__BB0_11:
	setp.eq.s32 	%p13, %r3522, 12;
	@%p13 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_12;

$L__BB0_17:
	add.s32 	%r104, %r780, -176418897;
	add.s32 	%r105, %r781, 1200080426;
	add.s32 	%r106, %r782, -1473231341;
	add.s32 	%r107, %r15, -1502002290;
	add.s32 	%r108, %r782, -1069501632;
	add.s32 	%r109, %r781, -701558691;
	add.s32 	%r110, %r780, -405537848;
	add.s32 	%r111, %r15, -1019803690;
	add.s32 	%r112, %r781, -378558;
	add.s32 	%r113, %r15, -35309556;
	add.s32 	%r114, %r780, 1272893353;
	add.s32 	%r115, %r782, 76029189;
	add.s32 	%r116, %r15, -1416354905;
	add.s32 	%r117, %r781, -57434055;
	add.s32 	%r118, %r782, -1560198380;
	add.s32 	%r119, %r780, -145523070;

$L__BB0_18:
	add.s32 	%r1950, %r3555, 1051707256;
	shf.l.wrap.b32 	%r1951, %r1950, %r1950, 7;
	add.s32 	%r1709, %r1951, -271733879;
	mov.u32 	%r1705, -271733879;
	and.b32  	%r1952, %r1709, 2004318071;
	xor.b32  	%r1953, %r1952, -1732584194;
	add.s32 	%r1954, %r3556, %r1953;
	add.s32 	%r1955, %r1954, -389564587;
	shf.l.wrap.b32 	%r1956, %r1955, %r1955, 12;
	add.s32 	%r1713, %r1956, %r1709;
	// begin inline asm
	lop3.b32 %r1702, %r1713, %r1709, %r1705, 202;
	// end inline asm
	add.s32 	%r1957, %r3557, %r1702;
	add.s32 	%r1958, %r1957, 1435904727;
	shf.l.wrap.b32 	%r1959, %r1958, %r1958, 17;
	add.s32 	%r1717, %r1713, %r1959;
	// begin inline asm
	lop3.b32 %r1706, %r1717, %r1713, %r1709, 202;
	// end inline asm
	add.s32 	%r1960, %r3558, %r1706;
	add.s32 	%r1961, %r1960, -1044525331;
	shf.l.wrap.b32 	%r1962, %r1961, %r1961, 22;
	add.s32 	%r1721, %r1717, %r1962;
	// begin inline asm
	lop3.b32 %r1710, %r1721, %r1717, %r1713, 202;
	// end inline asm
	add.s32 	%r1963, %r104, %r1709;
	add.s32 	%r1964, %r1963, %r1710;
	shf.l.wrap.b32 	%r1965, %r1964, %r1964, 7;
	add.s32 	%r1725, %r1721, %r1965;
	// begin inline asm
	lop3.b32 %r1714, %r1725, %r1721, %r1717, 202;
	// end inline asm
	add.s32 	%r1966, %r105, %r1714;
	add.s32 	%r1967, %r1966, %r1713;
	shf.l.wrap.b32 	%r1968, %r1967, %r1967, 12;
	add.s32 	%r1729, %r1968, %r1725;
	// begin inline asm
	lop3.b32 %r1718, %r1729, %r1725, %r1721, 202;
	// end inline asm
	add.s32 	%r1969, %r106, %r1718;
	add.s32 	%r1970, %r1969, %r1717;
	shf.l.wrap.b32 	%r1971, %r1970, %r1970, 17;
	add.s32 	%r1733, %r1971, %r1729;
	// begin inline asm
	lop3.b32 %r1722, %r1733, %r1729, %r1725, 202;
	// end inline asm
	add.s32 	%r1972, %r1722, %r1721;
	add.s32 	%r1973, %r1972, -45705855;
	shf.l.wrap.b32 	%r1974, %r1973, %r1973, 22;
	add.s32 	%r1737, %r1733, %r1974;
	// begin inline asm
	lop3.b32 %r1726, %r1737, %r1733, %r1729, 202;
	// end inline asm
	add.s32 	%r1975, %r1726, %r1725;
	add.s32 	%r1976, %r1975, 1770035416;
	shf.l.wrap.b32 	%r1977, %r1976, %r1976, 7;
	add.s32 	%r1741, %r1737, %r1977;
	// begin inline asm
	lop3.b32 %r1730, %r1741, %r1737, %r1733, 202;
	// end inline asm
	add.s32 	%r1978, %r1730, %r1729;
	add.s32 	%r1979, %r1978, -1958414417;
	shf.l.wrap.b32 	%r1980, %r1979, %r1979, 12;
	add.s32 	%r1745, %r1980, %r1741;
	// begin inline asm
	lop3.b32 %r1734, %r1745, %r1741, %r1737, 202;
	// end inline asm
	add.s32 	%r1981, %r1734, %r1733;
	add.s32 	%r1982, %r1981, -42063;
	shf.l.wrap.b32 	%r1983, %r1982, %r1982, 17;
	add.s32 	%r1749, %r1983, %r1745;
	// begin inline asm
	lop3.b32 %r1738, %r1749, %r1745, %r1741, 202;
	// end inline asm
	add.s32 	%r1984, %r1738, %r1737;
	add.s32 	%r1985, %r1984, -1990404162;
	shf.l.wrap.b32 	%r1986, %r1985, %r1985, 22;
	add.s32 	%r1753, %r1986, %r1749;
	// begin inline asm
	lop3.b32 %r1742, %r1753, %r1749, %r1745, 202;
	// end inline asm
	add.s32 	%r1987, %r1742, %r1741;
	add.s32 	%r1988, %r1987, 1804603682;
	shf.l.wrap.b32 	%r1989, %r1988, %r1988, 7;
	add.s32 	%r1757, %r1989, %r1753;
	// begin inline asm
	lop3.b32 %r1746, %r1757, %r1753, %r1749, 202;
	// end inline asm
	add.s32 	%r1990, %r1746, %r1745;
	add.s32 	%r1991, %r1990, -40341101;
	shf.l.wrap.b32 	%r1992, %r1991, %r1991, 12;
	add.s32 	%r1761, %r1992, %r1757;
	// begin inline asm
	lop3.b32 %r1750, %r1761, %r1757, %r1753, 202;
	// end inline asm
	add.s32 	%r1993, %r107, %r1750;
	add.s32 	%r1994, %r1993, %r1749;
	shf.l.wrap.b32 	%r1995, %r1994, %r1994, 17;
	add.s32 	%r1765, %r1995, %r1761;
	// begin inline asm
	lop3.b32 %r1754, %r1765, %r1761, %r1757, 202;
	// end inline asm
	add.s32 	%r1996, %r1754, %r1753;
	add.s32 	%r1997, %r1996, 1236535329;
	shf.l.wrap.b32 	%r1998, %r1997, %r1997, 22;
	add.s32 	%r1769, %r1765, %r1998;
	// begin inline asm
	lop3.b32 %r1758, %r1769, %r1765, %r1761, 228;
	// end inline asm
	add.s32 	%r1999, %r3556, %r1758;
	add.s32 	%r2000, %r1999, %r1757;
	add.s32 	%r2001, %r2000, -437530389;
	shf.l.wrap.b32 	%r2002, %r2001, %r2001, 5;
	add.s32 	%r1773, %r2002, %r1769;
	// begin inline asm
	lop3.b32 %r1762, %r1773, %r1769, %r1765, 228;
	// end inline asm
	add.s32 	%r2003, %r108, %r1762;
	add.s32 	%r2004, %r2003, %r1761;
	shf.l.wrap.b32 	%r2005, %r2004, %r2004, 9;
	add.s32 	%r1777, %r2005, %r1773;
	// begin inline asm
	lop3.b32 %r1766, %r1777, %r1773, %r1769, 228;
	// end inline asm
	add.s32 	%r2006, %r1766, %r1765;
	add.s32 	%r2007, %r2006, 643717713;
	shf.l.wrap.b32 	%r2008, %r2007, %r2007, 14;
	add.s32 	%r1781, %r2008, %r1777;
	// begin inline asm
	lop3.b32 %r1770, %r1781, %r1777, %r1773, 228;
	// end inline asm
	add.s32 	%r2009, %r3555, %r1770;
	add.s32 	%r2010, %r2009, %r1769;
	add.s32 	%r2011, %r2010, 1358686891;
	shf.l.wrap.b32 	%r2012, %r2011, %r2011, 20;
	add.s32 	%r1785, %r2012, %r1781;
	// begin inline asm
	lop3.b32 %r1774, %r1785, %r1781, %r1777, 228;
	// end inline asm
	add.s32 	%r2013, %r109, %r1774;
	add.s32 	%r2014, %r2013, %r1773;
	shf.l.wrap.b32 	%r2015, %r2014, %r2014, 5;
	add.s32 	%r1789, %r2015, %r1785;
	// begin inline asm
	lop3.b32 %r1778, %r1789, %r1785, %r1781, 228;
	// end inline asm
	add.s32 	%r2016, %r1778, %r1777;
	add.s32 	%r2017, %r2016, 38016083;
	shf.l.wrap.b32 	%r2018, %r2017, %r2017, 9;
	add.s32 	%r1793, %r1789, %r2018;
	// begin inline asm
	lop3.b32 %r1782, %r1793, %r1789, %r1785, 228;
	// end inline asm
	add.s32 	%r2019, %r1782, %r1781;
	add.s32 	%r2020, %r2019, -660478335;
	shf.l.wrap.b32 	%r2021, %r2020, %r2020, 14;
	add.s32 	%r1797, %r1793, %r2021;
	// begin inline asm
	lop3.b32 %r1786, %r1797, %r1793, %r1789, 228;
	// end inline asm
	add.s32 	%r2022, %r110, %r1786;
	add.s32 	%r2023, %r2022, %r1785;
	shf.l.wrap.b32 	%r2024, %r2023, %r2023, 20;
	add.s32 	%r1801, %r2024, %r1797;
	// begin inline asm
	lop3.b32 %r1790, %r1801, %r1797, %r1793, 228;
	// end inline asm
	add.s32 	%r2025, %r1790, %r1789;
	add.s32 	%r2026, %r2025, 568446438;
	shf.l.wrap.b32 	%r2027, %r2026, %r2026, 5;
	add.s32 	%r1805, %r1801, %r2027;
	// begin inline asm
	lop3.b32 %r1794, %r1805, %r1801, %r1797, 228;
	// end inline asm
	add.s32 	%r2028, %r111, %r1794;
	add.s32 	%r2029, %r2028, %r1793;
	shf.l.wrap.b32 	%r2030, %r2029, %r2029, 9;
	add.s32 	%r1809, %r2030, %r1805;
	// begin inline asm
	lop3.b32 %r1798, %r1809, %r1805, %r1801, 228;
	// end inline asm
	add.s32 	%r2031, %r3558, %r1798;
	add.s32 	%r2032, %r2031, %r1797;
	add.s32 	%r2033, %r2032, 84369917;
	shf.l.wrap.b32 	%r2034, %r2033, %r2033, 14;
	add.s32 	%r1813, %r2034, %r1809;
	// begin inline asm
	lop3.b32 %r1802, %r1813, %r1809, %r1805, 228;
	// end inline asm
	add.s32 	%r2035, %r1802, %r1801;
	add.s32 	%r2036, %r2035, 1163531501;
	shf.l.wrap.b32 	%r2037, %r2036, %r2036, 20;
	add.s32 	%r1817, %r2037, %r1813;
	// begin inline asm
	lop3.b32 %r1806, %r1817, %r1813, %r1809, 228;
	// end inline asm
	add.s32 	%r2038, %r1806, %r1805;
	add.s32 	%r2039, %r2038, -1444681467;
	shf.l.wrap.b32 	%r2040, %r2039, %r2039, 5;
	add.s32 	%r1821, %r2040, %r1817;
	// begin inline asm
	lop3.b32 %r1810, %r1821, %r1817, %r1813, 228;
	// end inline asm
	add.s32 	%r2041, %r3557, %r1810;
	add.s32 	%r2042, %r2041, %r1809;
	add.s32 	%r2043, %r2042, -1783987978;
	shf.l.wrap.b32 	%r2044, %r2043, %r2043, 9;
	add.s32 	%r1825, %r2044, %r1821;
	// begin inline asm
	lop3.b32 %r1814, %r1825, %r1821, %r1817, 228;
	// end inline asm
	add.s32 	%r2045, %r1814, %r1813;
	add.s32 	%r2046, %r2045, 1735328601;
	shf.l.wrap.b32 	%r2047, %r2046, %r2046, 14;
	add.s32 	%r1829, %r1825, %r2047;
	// begin inline asm
	lop3.b32 %r1818, %r1829, %r1825, %r1821, 228;
	// end inline asm
	add.s32 	%r2048, %r1818, %r1817;
	add.s32 	%r2049, %r2048, -1926607734;
	shf.l.wrap.b32 	%r2050, %r2049, %r2049, 20;
	add.s32 	%r1833, %r1829, %r2050;
	// begin inline asm
	lop3.b32 %r1822, %r1833, %r1829, %r1825, 150;
	// end inline asm
	add.s32 	%r2051, %r112, %r1822;
	add.s32 	%r2052, %r2051, %r1821;
	shf.l.wrap.b32 	%r2053, %r2052, %r2052, 4;
	add.s32 	%r1837, %r2053, %r1833;
	// begin inline asm
	lop3.b32 %r1826, %r1837, %r1833, %r1829, 150;
	// end inline asm
	add.s32 	%r2054, %r1826, %r1825;
	add.s32 	%r2055, %r2054, -2022574463;
	shf.l.wrap.b32 	%r2056, %r2055, %r2055, 11;
	add.s32 	%r1841, %r2056, %r1837;
	// begin inline asm
	lop3.b32 %r1830, %r1841, %r1837, %r1833, 150;
	// end inline asm
	add.s32 	%r2057, %r1830, %r1829;
	add.s32 	%r2058, %r2057, 1839030562;
	shf.l.wrap.b32 	%r2059, %r2058, %r2058, 16;
	add.s32 	%r1845, %r2059, %r1841;
	// begin inline asm
	lop3.b32 %r1834, %r1845, %r1841, %r1837, 150;
	// end inline asm
	add.s32 	%r2060, %r113, %r1834;
	add.s32 	%r2061, %r2060, %r1833;
	shf.l.wrap.b32 	%r2062, %r2061, %r2061, 23;
	add.s32 	%r1849, %r2062, %r1845;
	// begin inline asm
	lop3.b32 %r1838, %r1849, %r1845, %r1841, 150;
	// end inline asm
	add.s32 	%r2063, %r3556, %r1838;
	add.s32 	%r2064, %r2063, %r1837;
	add.s32 	%r2065, %r2064, -1802725939;
	shf.l.wrap.b32 	%r2066, %r2065, %r2065, 4;
	add.s32 	%r1853, %r2066, %r1849;
	// begin inline asm
	lop3.b32 %r1842, %r1853, %r1849, %r1845, 150;
	// end inline asm
	add.s32 	%r2067, %r114, %r1842;
	add.s32 	%r2068, %r2067, %r1841;
	shf.l.wrap.b32 	%r2069, %r2068, %r2068, 11;
	add.s32 	%r1857, %r2069, %r1853;
	// begin inline asm
	lop3.b32 %r1846, %r1857, %r1853, %r1849, 150;
	// end inline asm
	add.s32 	%r2070, %r1846, %r1845;
	add.s32 	%r2071, %r2070, -155497504;
	shf.l.wrap.b32 	%r2072, %r2071, %r2071, 16;
	add.s32 	%r1861, %r1857, %r2072;
	// begin inline asm
	lop3.b32 %r1850, %r1861, %r1857, %r1853, 150;
	// end inline asm
	add.s32 	%r2073, %r1850, %r1849;
	add.s32 	%r2074, %r2073, -1094730640;
	shf.l.wrap.b32 	%r2075, %r2074, %r2074, 23;
	add.s32 	%r1865, %r2075, %r1861;
	// begin inline asm
	lop3.b32 %r1854, %r1865, %r1861, %r1857, 150;
	// end inline asm
	add.s32 	%r2076, %r1854, %r1853;
	add.s32 	%r2077, %r2076, 681279174;
	shf.l.wrap.b32 	%r2078, %r2077, %r2077, 4;
	add.s32 	%r1869, %r2078, %r1865;
	// begin inline asm
	lop3.b32 %r1858, %r1869, %r1865, %r1861, 150;
	// end inline asm
	add.s32 	%r2079, %r3555, %r1858;
	add.s32 	%r2080, %r2079, %r1857;
	add.s32 	%r2081, %r2080, 1374046971;
	shf.l.wrap.b32 	%r2082, %r2081, %r2081, 11;
	add.s32 	%r1873, %r2082, %r1869;
	// begin inline asm
	lop3.b32 %r1862, %r1873, %r1869, %r1865, 150;
	// end inline asm
	add.s32 	%r2083, %r3558, %r1862;
	add.s32 	%r2084, %r2083, %r1861;
	add.s32 	%r2085, %r2084, -450788101;
	shf.l.wrap.b32 	%r2086, %r2085, %r2085, 16;
	add.s32 	%r1877, %r2086, %r1873;
	// begin inline asm
	lop3.b32 %r1866, %r1877, %r1873, %r1869, 150;
	// end inline asm
	add.s32 	%r2087, %r115, %r1866;
	add.s32 	%r2088, %r2087, %r1865;
	shf.l.wrap.b32 	%r2089, %r2088, %r2088, 23;
	add.s32 	%r1881, %r2089, %r1877;
	// begin inline asm
	lop3.b32 %r1870, %r1881, %r1877, %r1873, 150;
	// end inline asm
	add.s32 	%r2090, %r1870, %r1869;
	add.s32 	%r2091, %r2090, -640364487;
	shf.l.wrap.b32 	%r2092, %r2091, %r2091, 4;
	add.s32 	%r1885, %r1881, %r2092;
	// begin inline asm
	lop3.b32 %r1874, %r1885, %r1881, %r1877, 150;
	// end inline asm
	add.s32 	%r2093, %r1874, %r1873;
	add.s32 	%r2094, %r2093, -421815835;
	shf.l.wrap.b32 	%r2095, %r2094, %r2094, 11;
	add.s32 	%r1889, %r2095, %r1885;
	// begin inline asm
	lop3.b32 %r1878, %r1889, %r1885, %r1881, 150;
	// end inline asm
	add.s32 	%r2096, %r1878, %r1877;
	add.s32 	%r2097, %r2096, 530742520;
	shf.l.wrap.b32 	%r2098, %r2097, %r2097, 16;
	add.s32 	%r1893, %r2098, %r1889;
	// begin inline asm
	lop3.b32 %r1882, %r1893, %r1889, %r1885, 150;
	// end inline asm
	add.s32 	%r2099, %r3557, %r1882;
	add.s32 	%r2100, %r2099, %r1881;
	add.s32 	%r2101, %r2100, 1567044451;
	shf.l.wrap.b32 	%r2102, %r2101, %r2101, 23;
	add.s32 	%r1897, %r2102, %r1893;
	// begin inline asm
	lop3.b32 %r1886, %r1897, %r1893, %r1889, 57;
	// end inline asm
	add.s32 	%r2103, %r3555, %r1886;
	add.s32 	%r2104, %r2103, %r1885;
	add.s32 	%r2105, %r2104, 1533953349;
	shf.l.wrap.b32 	%r2106, %r2105, %r2105, 6;
	add.s32 	%r1901, %r2106, %r1897;
	// begin inline asm
	lop3.b32 %r1890, %r1901, %r1897, %r1893, 57;
	// end inline asm
	add.s32 	%r2107, %r1890, %r1889;
	add.s32 	%r2108, %r2107, 1126891543;
	shf.l.wrap.b32 	%r2109, %r2108, %r2108, 10;
	add.s32 	%r1905, %r1901, %r2109;
	// begin inline asm
	lop3.b32 %r1894, %r1905, %r1901, %r1897, 57;
	// end inline asm
	add.s32 	%r2110, %r116, %r1894;
	add.s32 	%r2111, %r2110, %r1893;
	shf.l.wrap.b32 	%r2112, %r2111, %r2111, 15;
	add.s32 	%r1909, %r2112, %r1905;
	// begin inline asm
	lop3.b32 %r1898, %r1909, %r1905, %r1901, 57;
	// end inline asm
	add.s32 	%r2113, %r117, %r1898;
	add.s32 	%r2114, %r2113, %r1897;
	shf.l.wrap.b32 	%r2115, %r2114, %r2114, 21;
	add.s32 	%r1913, %r2115, %r1909;
	// begin inline asm
	lop3.b32 %r1902, %r1913, %r1909, %r1905, 57;
	// end inline asm
	add.s32 	%r2116, %r1902, %r1901;
	add.s32 	%r2117, %r2116, 1700485571;
	shf.l.wrap.b32 	%r2118, %r2117, %r2117, 6;
	add.s32 	%r1917, %r1913, %r2118;
	// begin inline asm
	lop3.b32 %r1906, %r1917, %r1913, %r1909, 57;
	// end inline asm
	add.s32 	%r2119, %r3558, %r1906;
	add.s32 	%r2120, %r2119, %r1905;
	add.s32 	%r2121, %r2120, -1623252728;
	shf.l.wrap.b32 	%r2122, %r2121, %r2121, 10;
	add.s32 	%r1921, %r2122, %r1917;
	// begin inline asm
	lop3.b32 %r1910, %r1921, %r1917, %r1913, 57;
	// end inline asm
	add.s32 	%r2123, %r1910, %r1909;
	add.s32 	%r2124, %r2123, -1051523;
	shf.l.wrap.b32 	%r2125, %r2124, %r2124, 15;
	add.s32 	%r1925, %r1921, %r2125;
	// begin inline asm
	lop3.b32 %r1914, %r1925, %r1921, %r1917, 57;
	// end inline asm
	add.s32 	%r2126, %r3556, %r1914;
	add.s32 	%r2127, %r2126, %r1913;
	add.s32 	%r2128, %r2127, 1968310618;
	shf.l.wrap.b32 	%r2129, %r2128, %r2128, 21;
	add.s32 	%r1929, %r2129, %r1925;
	// begin inline asm
	lop3.b32 %r1918, %r1929, %r1925, %r1921, 57;
	// end inline asm
	add.s32 	%r2130, %r1918, %r1917;
	add.s32 	%r2131, %r2130, 1873313359;
	shf.l.wrap.b32 	%r2132, %r2131, %r2131, 6;
	add.s32 	%r1933, %r1929, %r2132;
	// begin inline asm
	lop3.b32 %r1922, %r1933, %r1929, %r1925, 57;
	// end inline asm
	add.s32 	%r2133, %r1922, %r1921;
	add.s32 	%r2134, %r2133, -30611744;
	shf.l.wrap.b32 	%r2135, %r2134, %r2134, 10;
	add.s32 	%r1937, %r1933, %r2135;
	// begin inline asm
	lop3.b32 %r1926, %r1937, %r1933, %r1929, 57;
	// end inline asm
	add.s32 	%r2136, %r118, %r1926;
	add.s32 	%r2137, %r2136, %r1925;
	shf.l.wrap.b32 	%r2138, %r2137, %r2137, 15;
	add.s32 	%r1941, %r2138, %r1937;
	// begin inline asm
	lop3.b32 %r1930, %r1941, %r1937, %r1933, 57;
	// end inline asm
	add.s32 	%r2139, %r1930, %r1929;
	add.s32 	%r2140, %r2139, 1309151649;
	shf.l.wrap.b32 	%r2141, %r2140, %r2140, 21;
	add.s32 	%r1945, %r2141, %r1941;
	// begin inline asm
	lop3.b32 %r1934, %r1945, %r1941, %r1937, 57;
	// end inline asm
	add.s32 	%r2142, %r119, %r1934;
	add.s32 	%r2143, %r2142, %r1933;
	shf.l.wrap.b32 	%r2144, %r2143, %r2143, 6;
	add.s32 	%r3555, %r2144, %r1945;
	// begin inline asm
	lop3.b32 %r1938, %r3555, %r1945, %r1941, 57;
	// end inline asm
	add.s32 	%r2145, %r1938, %r1937;
	add.s32 	%r2146, %r2145, -1120210379;
	shf.l.wrap.b32 	%r2147, %r2146, %r2146, 10;
	add.s32 	%r3558, %r3555, %r2147;
	// begin inline asm
	lop3.b32 %r1942, %r3558, %r3555, %r1945, 57;
	// end inline asm
	add.s32 	%r2148, %r3557, %r1942;
	add.s32 	%r2149, %r2148, %r1941;
	add.s32 	%r2150, %r2149, -1013796935;
	shf.l.wrap.b32 	%r2151, %r2150, %r2150, 15;
	add.s32 	%r3557, %r2151, %r3558;
	// begin inline asm
	lop3.b32 %r1946, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r2152, %r1946, %r1945;
	add.s32 	%r2153, %r2152, -343485551;
	shf.l.wrap.b32 	%r2154, %r2153, %r2153, 21;
	add.s32 	%r3556, %r3557, %r2154;
	add.s32 	%r2, %r2, -1;
	setp.eq.s32 	%p17, %r2, 0;
	@%p17 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_18;

$L__BB0_12:
	setp.lt.u32 	%p14, %r3521, 16;
	add.s32 	%r24, %r780, -176418897;
	add.s32 	%r25, %r781, 1200080426;
	add.s32 	%r26, %r782, -1473231341;
	add.s32 	%r27, %r783, -45705983;
	@%p14 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_13;

$L__BB0_15:
	add.s32 	%r78, %r15, -1502002290;
	add.s32 	%r79, %r782, -1069501632;
	add.s32 	%r80, %r781, -701558691;
	add.s32 	%r81, %r780, -405537848;
	add.s32 	%r82, %r15, -1019803690;
	add.s32 	%r83, %r783, 1735328473;
	add.s32 	%r84, %r781, -378558;
	add.s32 	%r85, %r15, -35309556;
	add.s32 	%r86, %r780, 1272893353;
	add.s32 	%r87, %r783, -155497632;
	add.s32 	%r88, %r782, 76029189;
	add.s32 	%r89, %r783, 1126891415;
	add.s32 	%r90, %r15, -1416354905;
	add.s32 	%r91, %r781, -57434055;
	add.s32 	%r92, %r782, -1560198380;
	add.s32 	%r93, %r780, -145523070;

$L__BB0_16:
	add.s32 	%r1497, %r3555, 1051707256;
	shf.l.wrap.b32 	%r1498, %r1497, %r1497, 7;
	add.s32 	%r1256, %r1498, -271733879;
	mov.u32 	%r1252, -271733879;
	and.b32  	%r1499, %r1256, 2004318071;
	xor.b32  	%r1500, %r1499, -1732584194;
	add.s32 	%r1501, %r3556, %r1500;
	add.s32 	%r1502, %r1501, -389564587;
	shf.l.wrap.b32 	%r1503, %r1502, %r1502, 12;
	add.s32 	%r1260, %r1503, %r1256;
	// begin inline asm
	lop3.b32 %r1249, %r1260, %r1256, %r1252, 202;
	// end inline asm
	add.s32 	%r1504, %r3557, %r1249;
	add.s32 	%r1505, %r1504, 1435904727;
	shf.l.wrap.b32 	%r1506, %r1505, %r1505, 17;
	add.s32 	%r1264, %r1260, %r1506;
	// begin inline asm
	lop3.b32 %r1253, %r1264, %r1260, %r1256, 202;
	// end inline asm
	add.s32 	%r1507, %r3558, %r1253;
	add.s32 	%r1508, %r1507, -1044525331;
	shf.l.wrap.b32 	%r1509, %r1508, %r1508, 22;
	add.s32 	%r1268, %r1264, %r1509;
	// begin inline asm
	lop3.b32 %r1257, %r1268, %r1264, %r1260, 202;
	// end inline asm
	add.s32 	%r1510, %r24, %r1256;
	add.s32 	%r1511, %r1510, %r1257;
	shf.l.wrap.b32 	%r1512, %r1511, %r1511, 7;
	add.s32 	%r1272, %r1268, %r1512;
	// begin inline asm
	lop3.b32 %r1261, %r1272, %r1268, %r1264, 202;
	// end inline asm
	add.s32 	%r1513, %r25, %r1261;
	add.s32 	%r1514, %r1513, %r1260;
	shf.l.wrap.b32 	%r1515, %r1514, %r1514, 12;
	add.s32 	%r1276, %r1515, %r1272;
	// begin inline asm
	lop3.b32 %r1265, %r1276, %r1272, %r1268, 202;
	// end inline asm
	add.s32 	%r1516, %r26, %r1265;
	add.s32 	%r1517, %r1516, %r1264;
	shf.l.wrap.b32 	%r1518, %r1517, %r1517, 17;
	add.s32 	%r1280, %r1518, %r1276;
	// begin inline asm
	lop3.b32 %r1269, %r1280, %r1276, %r1272, 202;
	// end inline asm
	add.s32 	%r1519, %r27, %r1269;
	add.s32 	%r1520, %r1519, %r1268;
	shf.l.wrap.b32 	%r1521, %r1520, %r1520, 22;
	add.s32 	%r1284, %r1521, %r1280;
	// begin inline asm
	lop3.b32 %r1273, %r1284, %r1280, %r1276, 202;
	// end inline asm
	add.s32 	%r1522, %r1273, %r1272;
	add.s32 	%r1523, %r1522, 1770035416;
	shf.l.wrap.b32 	%r1524, %r1523, %r1523, 7;
	add.s32 	%r1288, %r1284, %r1524;
	// begin inline asm
	lop3.b32 %r1277, %r1288, %r1284, %r1280, 202;
	// end inline asm
	add.s32 	%r1525, %r1277, %r1276;
	add.s32 	%r1526, %r1525, -1958414417;
	shf.l.wrap.b32 	%r1527, %r1526, %r1526, 12;
	add.s32 	%r1292, %r1527, %r1288;
	// begin inline asm
	lop3.b32 %r1281, %r1292, %r1288, %r1284, 202;
	// end inline asm
	add.s32 	%r1528, %r1281, %r1280;
	add.s32 	%r1529, %r1528, -42063;
	shf.l.wrap.b32 	%r1530, %r1529, %r1529, 17;
	add.s32 	%r1296, %r1530, %r1292;
	// begin inline asm
	lop3.b32 %r1285, %r1296, %r1292, %r1288, 202;
	// end inline asm
	add.s32 	%r1531, %r1285, %r1284;
	add.s32 	%r1532, %r1531, -1990404162;
	shf.l.wrap.b32 	%r1533, %r1532, %r1532, 22;
	add.s32 	%r1300, %r1533, %r1296;
	// begin inline asm
	lop3.b32 %r1289, %r1300, %r1296, %r1292, 202;
	// end inline asm
	add.s32 	%r1534, %r1289, %r1288;
	add.s32 	%r1535, %r1534, 1804603682;
	shf.l.wrap.b32 	%r1536, %r1535, %r1535, 7;
	add.s32 	%r1304, %r1536, %r1300;
	// begin inline asm
	lop3.b32 %r1293, %r1304, %r1300, %r1296, 202;
	// end inline asm
	add.s32 	%r1537, %r1293, %r1292;
	add.s32 	%r1538, %r1537, -40341101;
	shf.l.wrap.b32 	%r1539, %r1538, %r1538, 12;
	add.s32 	%r1308, %r1539, %r1304;
	// begin inline asm
	lop3.b32 %r1297, %r1308, %r1304, %r1300, 202;
	// end inline asm
	add.s32 	%r1540, %r78, %r1297;
	add.s32 	%r1541, %r1540, %r1296;
	shf.l.wrap.b32 	%r1542, %r1541, %r1541, 17;
	add.s32 	%r1312, %r1542, %r1308;
	// begin inline asm
	lop3.b32 %r1301, %r1312, %r1308, %r1304, 202;
	// end inline asm
	add.s32 	%r1543, %r1301, %r1300;
	add.s32 	%r1544, %r1543, 1236535329;
	shf.l.wrap.b32 	%r1545, %r1544, %r1544, 22;
	add.s32 	%r1316, %r1312, %r1545;
	// begin inline asm
	lop3.b32 %r1305, %r1316, %r1312, %r1308, 228;
	// end inline asm
	add.s32 	%r1546, %r3556, %r1305;
	add.s32 	%r1547, %r1546, %r1304;
	add.s32 	%r1548, %r1547, -437530389;
	shf.l.wrap.b32 	%r1549, %r1548, %r1548, 5;
	add.s32 	%r1320, %r1549, %r1316;
	// begin inline asm
	lop3.b32 %r1309, %r1320, %r1316, %r1312, 228;
	// end inline asm
	add.s32 	%r1550, %r79, %r1309;
	add.s32 	%r1551, %r1550, %r1308;
	shf.l.wrap.b32 	%r1552, %r1551, %r1551, 9;
	add.s32 	%r1324, %r1552, %r1320;
	// begin inline asm
	lop3.b32 %r1313, %r1324, %r1320, %r1316, 228;
	// end inline asm
	add.s32 	%r1553, %r1313, %r1312;
	add.s32 	%r1554, %r1553, 643717713;
	shf.l.wrap.b32 	%r1555, %r1554, %r1554, 14;
	add.s32 	%r1328, %r1555, %r1324;
	// begin inline asm
	lop3.b32 %r1317, %r1328, %r1324, %r1320, 228;
	// end inline asm
	add.s32 	%r1556, %r3555, %r1317;
	add.s32 	%r1557, %r1556, %r1316;
	add.s32 	%r1558, %r1557, 1358686891;
	shf.l.wrap.b32 	%r1559, %r1558, %r1558, 20;
	add.s32 	%r1332, %r1559, %r1328;
	// begin inline asm
	lop3.b32 %r1321, %r1332, %r1328, %r1324, 228;
	// end inline asm
	add.s32 	%r1560, %r80, %r1321;
	add.s32 	%r1561, %r1560, %r1320;
	shf.l.wrap.b32 	%r1562, %r1561, %r1561, 5;
	add.s32 	%r1336, %r1562, %r1332;
	// begin inline asm
	lop3.b32 %r1325, %r1336, %r1332, %r1328, 228;
	// end inline asm
	add.s32 	%r1563, %r1325, %r1324;
	add.s32 	%r1564, %r1563, 38016083;
	shf.l.wrap.b32 	%r1565, %r1564, %r1564, 9;
	add.s32 	%r1340, %r1336, %r1565;
	// begin inline asm
	lop3.b32 %r1329, %r1340, %r1336, %r1332, 228;
	// end inline asm
	add.s32 	%r1566, %r1329, %r1328;
	add.s32 	%r1567, %r1566, -660478335;
	shf.l.wrap.b32 	%r1568, %r1567, %r1567, 14;
	add.s32 	%r1344, %r1340, %r1568;
	// begin inline asm
	lop3.b32 %r1333, %r1344, %r1340, %r1336, 228;
	// end inline asm
	add.s32 	%r1569, %r81, %r1333;
	add.s32 	%r1570, %r1569, %r1332;
	shf.l.wrap.b32 	%r1571, %r1570, %r1570, 20;
	add.s32 	%r1348, %r1571, %r1344;
	// begin inline asm
	lop3.b32 %r1337, %r1348, %r1344, %r1340, 228;
	// end inline asm
	add.s32 	%r1572, %r1337, %r1336;
	add.s32 	%r1573, %r1572, 568446438;
	shf.l.wrap.b32 	%r1574, %r1573, %r1573, 5;
	add.s32 	%r1352, %r1348, %r1574;
	// begin inline asm
	lop3.b32 %r1341, %r1352, %r1348, %r1344, 228;
	// end inline asm
	add.s32 	%r1575, %r82, %r1341;
	add.s32 	%r1576, %r1575, %r1340;
	shf.l.wrap.b32 	%r1577, %r1576, %r1576, 9;
	add.s32 	%r1356, %r1577, %r1352;
	// begin inline asm
	lop3.b32 %r1345, %r1356, %r1352, %r1348, 228;
	// end inline asm
	add.s32 	%r1578, %r3558, %r1345;
	add.s32 	%r1579, %r1578, %r1344;
	add.s32 	%r1580, %r1579, 84369917;
	shf.l.wrap.b32 	%r1581, %r1580, %r1580, 14;
	add.s32 	%r1360, %r1581, %r1356;
	// begin inline asm
	lop3.b32 %r1349, %r1360, %r1356, %r1352, 228;
	// end inline asm
	add.s32 	%r1582, %r1349, %r1348;
	add.s32 	%r1583, %r1582, 1163531501;
	shf.l.wrap.b32 	%r1584, %r1583, %r1583, 20;
	add.s32 	%r1364, %r1584, %r1360;
	// begin inline asm
	lop3.b32 %r1353, %r1364, %r1360, %r1356, 228;
	// end inline asm
	add.s32 	%r1585, %r1353, %r1352;
	add.s32 	%r1586, %r1585, -1444681467;
	shf.l.wrap.b32 	%r1587, %r1586, %r1586, 5;
	add.s32 	%r1368, %r1587, %r1364;
	// begin inline asm
	lop3.b32 %r1357, %r1368, %r1364, %r1360, 228;
	// end inline asm
	add.s32 	%r1588, %r3557, %r1357;
	add.s32 	%r1589, %r1588, %r1356;
	add.s32 	%r1590, %r1589, -1783987978;
	shf.l.wrap.b32 	%r1591, %r1590, %r1590, 9;
	add.s32 	%r1372, %r1591, %r1368;
	// begin inline asm
	lop3.b32 %r1361, %r1372, %r1368, %r1364, 228;
	// end inline asm
	add.s32 	%r1592, %r83, %r1361;
	add.s32 	%r1593, %r1592, %r1360;
	shf.l.wrap.b32 	%r1594, %r1593, %r1593, 14;
	add.s32 	%r1376, %r1594, %r1372;
	// begin inline asm
	lop3.b32 %r1365, %r1376, %r1372, %r1368, 228;
	// end inline asm
	add.s32 	%r1595, %r1365, %r1364;
	add.s32 	%r1596, %r1595, -1926607734;
	shf.l.wrap.b32 	%r1597, %r1596, %r1596, 20;
	add.s32 	%r1380, %r1376, %r1597;
	// begin inline asm
	lop3.b32 %r1369, %r1380, %r1376, %r1372, 150;
	// end inline asm
	add.s32 	%r1598, %r84, %r1369;
	add.s32 	%r1599, %r1598, %r1368;
	shf.l.wrap.b32 	%r1600, %r1599, %r1599, 4;
	add.s32 	%r1384, %r1600, %r1380;
	// begin inline asm
	lop3.b32 %r1373, %r1384, %r1380, %r1376, 150;
	// end inline asm
	add.s32 	%r1601, %r1373, %r1372;
	add.s32 	%r1602, %r1601, -2022574463;
	shf.l.wrap.b32 	%r1603, %r1602, %r1602, 11;
	add.s32 	%r1388, %r1603, %r1384;
	// begin inline asm
	lop3.b32 %r1377, %r1388, %r1384, %r1380, 150;
	// end inline asm
	add.s32 	%r1604, %r1377, %r1376;
	add.s32 	%r1605, %r1604, 1839030562;
	shf.l.wrap.b32 	%r1606, %r1605, %r1605, 16;
	add.s32 	%r1392, %r1606, %r1388;
	// begin inline asm
	lop3.b32 %r1381, %r1392, %r1388, %r1384, 150;
	// end inline asm
	add.s32 	%r1607, %r85, %r1381;
	add.s32 	%r1608, %r1607, %r1380;
	shf.l.wrap.b32 	%r1609, %r1608, %r1608, 23;
	add.s32 	%r1396, %r1609, %r1392;
	// begin inline asm
	lop3.b32 %r1385, %r1396, %r1392, %r1388, 150;
	// end inline asm
	add.s32 	%r1610, %r3556, %r1385;
	add.s32 	%r1611, %r1610, %r1384;
	add.s32 	%r1612, %r1611, -1802725939;
	shf.l.wrap.b32 	%r1613, %r1612, %r1612, 4;
	add.s32 	%r1400, %r1613, %r1396;
	// begin inline asm
	lop3.b32 %r1389, %r1400, %r1396, %r1392, 150;
	// end inline asm
	add.s32 	%r1614, %r86, %r1389;
	add.s32 	%r1615, %r1614, %r1388;
	shf.l.wrap.b32 	%r1616, %r1615, %r1615, 11;
	add.s32 	%r1404, %r1616, %r1400;
	// begin inline asm
	lop3.b32 %r1393, %r1404, %r1400, %r1396, 150;
	// end inline asm
	add.s32 	%r1617, %r87, %r1393;
	add.s32 	%r1618, %r1617, %r1392;
	shf.l.wrap.b32 	%r1619, %r1618, %r1618, 16;
	add.s32 	%r1408, %r1619, %r1404;
	// begin inline asm
	lop3.b32 %r1397, %r1408, %r1404, %r1400, 150;
	// end inline asm
	add.s32 	%r1620, %r1397, %r1396;
	add.s32 	%r1621, %r1620, -1094730640;
	shf.l.wrap.b32 	%r1622, %r1621, %r1621, 23;
	add.s32 	%r1412, %r1622, %r1408;
	// begin inline asm
	lop3.b32 %r1401, %r1412, %r1408, %r1404, 150;
	// end inline asm
	add.s32 	%r1623, %r1401, %r1400;
	add.s32 	%r1624, %r1623, 681279174;
	shf.l.wrap.b32 	%r1625, %r1624, %r1624, 4;
	add.s32 	%r1416, %r1625, %r1412;
	// begin inline asm
	lop3.b32 %r1405, %r1416, %r1412, %r1408, 150;
	// end inline asm
	add.s32 	%r1626, %r3555, %r1405;
	add.s32 	%r1627, %r1626, %r1404;
	add.s32 	%r1628, %r1627, 1374046971;
	shf.l.wrap.b32 	%r1629, %r1628, %r1628, 11;
	add.s32 	%r1420, %r1629, %r1416;
	// begin inline asm
	lop3.b32 %r1409, %r1420, %r1416, %r1412, 150;
	// end inline asm
	add.s32 	%r1630, %r3558, %r1409;
	add.s32 	%r1631, %r1630, %r1408;
	add.s32 	%r1632, %r1631, -450788101;
	shf.l.wrap.b32 	%r1633, %r1632, %r1632, 16;
	add.s32 	%r1424, %r1633, %r1420;
	// begin inline asm
	lop3.b32 %r1413, %r1424, %r1420, %r1416, 150;
	// end inline asm
	add.s32 	%r1634, %r88, %r1413;
	add.s32 	%r1635, %r1634, %r1412;
	shf.l.wrap.b32 	%r1636, %r1635, %r1635, 23;
	add.s32 	%r1428, %r1636, %r1424;
	// begin inline asm
	lop3.b32 %r1417, %r1428, %r1424, %r1420, 150;
	// end inline asm
	add.s32 	%r1637, %r1417, %r1416;
	add.s32 	%r1638, %r1637, -640364487;
	shf.l.wrap.b32 	%r1639, %r1638, %r1638, 4;
	add.s32 	%r1432, %r1428, %r1639;
	// begin inline asm
	lop3.b32 %r1421, %r1432, %r1428, %r1424, 150;
	// end inline asm
	add.s32 	%r1640, %r1421, %r1420;
	add.s32 	%r1641, %r1640, -421815835;
	shf.l.wrap.b32 	%r1642, %r1641, %r1641, 11;
	add.s32 	%r1436, %r1642, %r1432;
	// begin inline asm
	lop3.b32 %r1425, %r1436, %r1432, %r1428, 150;
	// end inline asm
	add.s32 	%r1643, %r1425, %r1424;
	add.s32 	%r1644, %r1643, 530742520;
	shf.l.wrap.b32 	%r1645, %r1644, %r1644, 16;
	add.s32 	%r1440, %r1645, %r1436;
	// begin inline asm
	lop3.b32 %r1429, %r1440, %r1436, %r1432, 150;
	// end inline asm
	add.s32 	%r1646, %r3557, %r1429;
	add.s32 	%r1647, %r1646, %r1428;
	add.s32 	%r1648, %r1647, 1567044451;
	shf.l.wrap.b32 	%r1649, %r1648, %r1648, 23;
	add.s32 	%r1444, %r1649, %r1440;
	// begin inline asm
	lop3.b32 %r1433, %r1444, %r1440, %r1436, 57;
	// end inline asm
	add.s32 	%r1650, %r3555, %r1433;
	add.s32 	%r1651, %r1650, %r1432;
	add.s32 	%r1652, %r1651, 1533953349;
	shf.l.wrap.b32 	%r1653, %r1652, %r1652, 6;
	add.s32 	%r1448, %r1653, %r1444;
	// begin inline asm
	lop3.b32 %r1437, %r1448, %r1444, %r1440, 57;
	// end inline asm
	add.s32 	%r1654, %r89, %r1437;
	add.s32 	%r1655, %r1654, %r1436;
	shf.l.wrap.b32 	%r1656, %r1655, %r1655, 10;
	add.s32 	%r1452, %r1656, %r1448;
	// begin inline asm
	lop3.b32 %r1441, %r1452, %r1448, %r1444, 57;
	// end inline asm
	add.s32 	%r1657, %r90, %r1441;
	add.s32 	%r1658, %r1657, %r1440;
	shf.l.wrap.b32 	%r1659, %r1658, %r1658, 15;
	add.s32 	%r1456, %r1659, %r1452;
	// begin inline asm
	lop3.b32 %r1445, %r1456, %r1452, %r1448, 57;
	// end inline asm
	add.s32 	%r1660, %r91, %r1445;
	add.s32 	%r1661, %r1660, %r1444;
	shf.l.wrap.b32 	%r1662, %r1661, %r1661, 21;
	add.s32 	%r1460, %r1662, %r1456;
	// begin inline asm
	lop3.b32 %r1449, %r1460, %r1456, %r1452, 57;
	// end inline asm
	add.s32 	%r1663, %r1449, %r1448;
	add.s32 	%r1664, %r1663, 1700485571;
	shf.l.wrap.b32 	%r1665, %r1664, %r1664, 6;
	add.s32 	%r1464, %r1460, %r1665;
	// begin inline asm
	lop3.b32 %r1453, %r1464, %r1460, %r1456, 57;
	// end inline asm
	add.s32 	%r1666, %r3558, %r1453;
	add.s32 	%r1667, %r1666, %r1452;
	add.s32 	%r1668, %r1667, -1623252728;
	shf.l.wrap.b32 	%r1669, %r1668, %r1668, 10;
	add.s32 	%r1468, %r1669, %r1464;
	// begin inline asm
	lop3.b32 %r1457, %r1468, %r1464, %r1460, 57;
	// end inline asm
	add.s32 	%r1670, %r1457, %r1456;
	add.s32 	%r1671, %r1670, -1051523;
	shf.l.wrap.b32 	%r1672, %r1671, %r1671, 15;
	add.s32 	%r1472, %r1468, %r1672;
	// begin inline asm
	lop3.b32 %r1461, %r1472, %r1468, %r1464, 57;
	// end inline asm
	add.s32 	%r1673, %r3556, %r1461;
	add.s32 	%r1674, %r1673, %r1460;
	add.s32 	%r1675, %r1674, 1968310618;
	shf.l.wrap.b32 	%r1676, %r1675, %r1675, 21;
	add.s32 	%r1476, %r1676, %r1472;
	// begin inline asm
	lop3.b32 %r1465, %r1476, %r1472, %r1468, 57;
	// end inline asm
	add.s32 	%r1677, %r1465, %r1464;
	add.s32 	%r1678, %r1677, 1873313359;
	shf.l.wrap.b32 	%r1679, %r1678, %r1678, 6;
	add.s32 	%r1480, %r1476, %r1679;
	// begin inline asm
	lop3.b32 %r1469, %r1480, %r1476, %r1472, 57;
	// end inline asm
	add.s32 	%r1680, %r1469, %r1468;
	add.s32 	%r1681, %r1680, -30611744;
	shf.l.wrap.b32 	%r1682, %r1681, %r1681, 10;
	add.s32 	%r1484, %r1480, %r1682;
	// begin inline asm
	lop3.b32 %r1473, %r1484, %r1480, %r1476, 57;
	// end inline asm
	add.s32 	%r1683, %r92, %r1473;
	add.s32 	%r1684, %r1683, %r1472;
	shf.l.wrap.b32 	%r1685, %r1684, %r1684, 15;
	add.s32 	%r1488, %r1685, %r1484;
	// begin inline asm
	lop3.b32 %r1477, %r1488, %r1484, %r1480, 57;
	// end inline asm
	add.s32 	%r1686, %r1477, %r1476;
	add.s32 	%r1687, %r1686, 1309151649;
	shf.l.wrap.b32 	%r1688, %r1687, %r1687, 21;
	add.s32 	%r1492, %r1688, %r1488;
	// begin inline asm
	lop3.b32 %r1481, %r1492, %r1488, %r1484, 57;
	// end inline asm
	add.s32 	%r1689, %r93, %r1481;
	add.s32 	%r1690, %r1689, %r1480;
	shf.l.wrap.b32 	%r1691, %r1690, %r1690, 6;
	add.s32 	%r3555, %r1691, %r1492;
	// begin inline asm
	lop3.b32 %r1485, %r3555, %r1492, %r1488, 57;
	// end inline asm
	add.s32 	%r1692, %r1485, %r1484;
	add.s32 	%r1693, %r1692, -1120210379;
	shf.l.wrap.b32 	%r1694, %r1693, %r1693, 10;
	add.s32 	%r3558, %r3555, %r1694;
	// begin inline asm
	lop3.b32 %r1489, %r3558, %r3555, %r1492, 57;
	// end inline asm
	add.s32 	%r1695, %r3557, %r1489;
	add.s32 	%r1696, %r1695, %r1488;
	add.s32 	%r1697, %r1696, -1013796935;
	shf.l.wrap.b32 	%r1698, %r1697, %r1697, 15;
	add.s32 	%r3557, %r1698, %r3558;
	// begin inline asm
	lop3.b32 %r1493, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r1699, %r1493, %r1492;
	add.s32 	%r1700, %r1699, -343485551;
	shf.l.wrap.b32 	%r1701, %r1700, %r1700, 21;
	add.s32 	%r3556, %r3557, %r1701;
	add.s32 	%r2, %r2, -1;
	setp.eq.s32 	%p16, %r2, 0;
	@%p16 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_16;

$L__BB0_13:
	ld.local.v2.u32 	{%r784, %r785}, [%rd5+32];
	ld.local.v2.u32 	{%r788, %r789}, [%rd5+40];
	ld.local.v2.u32 	{%r792, %r793}, [%rd5+48];
	add.s32 	%r28, %r784, 1770035416;
	add.s32 	%r29, %r785, -1958414417;
	add.s32 	%r30, %r788, -42063;
	add.s32 	%r31, %r789, -1990404162;
	add.s32 	%r32, %r792, 1804603682;
	add.s32 	%r33, %r793, -40341101;
	add.s32 	%r34, %r15, -1502002290;
	add.s32 	%r35, %r782, -1069501632;
	add.s32 	%r36, %r789, 643717713;
	add.s32 	%r37, %r781, -701558691;
	add.s32 	%r38, %r788, 38016083;
	add.s32 	%r39, %r780, -405537848;
	add.s32 	%r40, %r785, 568446438;
	add.s32 	%r41, %r15, -1019803690;
	add.s32 	%r42, %r784, 1163531501;
	add.s32 	%r43, %r793, -1444681467;
	add.s32 	%r44, %r783, 1735328473;
	add.s32 	%r45, %r792, -1926607734;
	add.s32 	%r46, %r781, -378558;
	add.s32 	%r47, %r784, -2022574463;
	add.s32 	%r48, %r789, 1839030562;
	add.s32 	%r49, %r15, -35309556;
	add.s32 	%r50, %r780, 1272893353;
	add.s32 	%r51, %r783, -155497632;
	add.s32 	%r52, %r788, -1094730640;
	add.s32 	%r53, %r793, 681279174;
	add.s32 	%r54, %r782, 76029189;
	add.s32 	%r55, %r785, -640364487;
	add.s32 	%r56, %r792, -421815835;
	add.s32 	%r57, %r783, 1126891415;
	add.s32 	%r58, %r15, -1416354905;
	add.s32 	%r59, %r781, -57434055;
	add.s32 	%r60, %r792, 1700485571;
	add.s32 	%r61, %r788, -1051523;
	add.s32 	%r62, %r784, 1873313359;
	add.s32 	%r63, %r782, -1560198380;
	add.s32 	%r64, %r793, 1309151649;
	add.s32 	%r65, %r780, -145523070;
	add.s32 	%r66, %r789, -1120210379;
	add.s32 	%r67, %r785, -343485551;

$L__BB0_14:
	add.s32 	%r1044, %r3555, 1051707256;
	shf.l.wrap.b32 	%r1045, %r1044, %r1044, 7;
	add.s32 	%r803, %r1045, -271733879;
	mov.u32 	%r799, -271733879;
	and.b32  	%r1046, %r803, 2004318071;
	xor.b32  	%r1047, %r1046, -1732584194;
	add.s32 	%r1048, %r3556, %r1047;
	add.s32 	%r1049, %r1048, -389564587;
	shf.l.wrap.b32 	%r1050, %r1049, %r1049, 12;
	add.s32 	%r807, %r1050, %r803;
	// begin inline asm
	lop3.b32 %r796, %r807, %r803, %r799, 202;
	// end inline asm
	add.s32 	%r1051, %r3557, %r796;
	add.s32 	%r1052, %r1051, 1435904727;
	shf.l.wrap.b32 	%r1053, %r1052, %r1052, 17;
	add.s32 	%r811, %r807, %r1053;
	// begin inline asm
	lop3.b32 %r800, %r811, %r807, %r803, 202;
	// end inline asm
	add.s32 	%r1054, %r3558, %r800;
	add.s32 	%r1055, %r1054, -1044525331;
	shf.l.wrap.b32 	%r1056, %r1055, %r1055, 22;
	add.s32 	%r815, %r811, %r1056;
	// begin inline asm
	lop3.b32 %r804, %r815, %r811, %r807, 202;
	// end inline asm
	add.s32 	%r1057, %r24, %r803;
	add.s32 	%r1058, %r1057, %r804;
	shf.l.wrap.b32 	%r1059, %r1058, %r1058, 7;
	add.s32 	%r819, %r815, %r1059;
	// begin inline asm
	lop3.b32 %r808, %r819, %r815, %r811, 202;
	// end inline asm
	add.s32 	%r1060, %r25, %r808;
	add.s32 	%r1061, %r1060, %r807;
	shf.l.wrap.b32 	%r1062, %r1061, %r1061, 12;
	add.s32 	%r823, %r1062, %r819;
	// begin inline asm
	lop3.b32 %r812, %r823, %r819, %r815, 202;
	// end inline asm
	add.s32 	%r1063, %r26, %r812;
	add.s32 	%r1064, %r1063, %r811;
	shf.l.wrap.b32 	%r1065, %r1064, %r1064, 17;
	add.s32 	%r827, %r1065, %r823;
	// begin inline asm
	lop3.b32 %r816, %r827, %r823, %r819, 202;
	// end inline asm
	add.s32 	%r1066, %r27, %r816;
	add.s32 	%r1067, %r1066, %r815;
	shf.l.wrap.b32 	%r1068, %r1067, %r1067, 22;
	add.s32 	%r831, %r1068, %r827;
	// begin inline asm
	lop3.b32 %r820, %r831, %r827, %r823, 202;
	// end inline asm
	add.s32 	%r1069, %r28, %r820;
	add.s32 	%r1070, %r1069, %r819;
	shf.l.wrap.b32 	%r1071, %r1070, %r1070, 7;
	add.s32 	%r835, %r1071, %r831;
	// begin inline asm
	lop3.b32 %r824, %r835, %r831, %r827, 202;
	// end inline asm
	add.s32 	%r1072, %r29, %r824;
	add.s32 	%r1073, %r1072, %r823;
	shf.l.wrap.b32 	%r1074, %r1073, %r1073, 12;
	add.s32 	%r839, %r1074, %r835;
	// begin inline asm
	lop3.b32 %r828, %r839, %r835, %r831, 202;
	// end inline asm
	add.s32 	%r1075, %r30, %r828;
	add.s32 	%r1076, %r1075, %r827;
	shf.l.wrap.b32 	%r1077, %r1076, %r1076, 17;
	add.s32 	%r843, %r1077, %r839;
	// begin inline asm
	lop3.b32 %r832, %r843, %r839, %r835, 202;
	// end inline asm
	add.s32 	%r1078, %r31, %r832;
	add.s32 	%r1079, %r1078, %r831;
	shf.l.wrap.b32 	%r1080, %r1079, %r1079, 22;
	add.s32 	%r847, %r1080, %r843;
	// begin inline asm
	lop3.b32 %r836, %r847, %r843, %r839, 202;
	// end inline asm
	add.s32 	%r1081, %r32, %r836;
	add.s32 	%r1082, %r1081, %r835;
	shf.l.wrap.b32 	%r1083, %r1082, %r1082, 7;
	add.s32 	%r851, %r1083, %r847;
	// begin inline asm
	lop3.b32 %r840, %r851, %r847, %r843, 202;
	// end inline asm
	add.s32 	%r1084, %r33, %r840;
	add.s32 	%r1085, %r1084, %r839;
	shf.l.wrap.b32 	%r1086, %r1085, %r1085, 12;
	add.s32 	%r855, %r1086, %r851;
	// begin inline asm
	lop3.b32 %r844, %r855, %r851, %r847, 202;
	// end inline asm
	add.s32 	%r1087, %r34, %r844;
	add.s32 	%r1088, %r1087, %r843;
	shf.l.wrap.b32 	%r1089, %r1088, %r1088, 17;
	add.s32 	%r859, %r1089, %r855;
	// begin inline asm
	lop3.b32 %r848, %r859, %r855, %r851, 202;
	// end inline asm
	add.s32 	%r1090, %r848, %r847;
	add.s32 	%r1091, %r1090, 1236535329;
	shf.l.wrap.b32 	%r1092, %r1091, %r1091, 22;
	add.s32 	%r863, %r859, %r1092;
	// begin inline asm
	lop3.b32 %r852, %r863, %r859, %r855, 228;
	// end inline asm
	add.s32 	%r1093, %r3556, %r852;
	add.s32 	%r1094, %r1093, %r851;
	add.s32 	%r1095, %r1094, -437530389;
	shf.l.wrap.b32 	%r1096, %r1095, %r1095, 5;
	add.s32 	%r867, %r1096, %r863;
	// begin inline asm
	lop3.b32 %r856, %r867, %r863, %r859, 228;
	// end inline asm
	add.s32 	%r1097, %r35, %r856;
	add.s32 	%r1098, %r1097, %r855;
	shf.l.wrap.b32 	%r1099, %r1098, %r1098, 9;
	add.s32 	%r871, %r1099, %r867;
	// begin inline asm
	lop3.b32 %r860, %r871, %r867, %r863, 228;
	// end inline asm
	add.s32 	%r1100, %r36, %r860;
	add.s32 	%r1101, %r1100, %r859;
	shf.l.wrap.b32 	%r1102, %r1101, %r1101, 14;
	add.s32 	%r875, %r1102, %r871;
	// begin inline asm
	lop3.b32 %r864, %r875, %r871, %r867, 228;
	// end inline asm
	add.s32 	%r1103, %r3555, %r864;
	add.s32 	%r1104, %r1103, %r863;
	add.s32 	%r1105, %r1104, 1358686891;
	shf.l.wrap.b32 	%r1106, %r1105, %r1105, 20;
	add.s32 	%r879, %r1106, %r875;
	// begin inline asm
	lop3.b32 %r868, %r879, %r875, %r871, 228;
	// end inline asm
	add.s32 	%r1107, %r37, %r868;
	add.s32 	%r1108, %r1107, %r867;
	shf.l.wrap.b32 	%r1109, %r1108, %r1108, 5;
	add.s32 	%r883, %r1109, %r879;
	// begin inline asm
	lop3.b32 %r872, %r883, %r879, %r875, 228;
	// end inline asm
	add.s32 	%r1110, %r38, %r872;
	add.s32 	%r1111, %r1110, %r871;
	shf.l.wrap.b32 	%r1112, %r1111, %r1111, 9;
	add.s32 	%r887, %r1112, %r883;
	// begin inline asm
	lop3.b32 %r876, %r887, %r883, %r879, 228;
	// end inline asm
	add.s32 	%r1113, %r876, %r875;
	add.s32 	%r1114, %r1113, -660478335;
	shf.l.wrap.b32 	%r1115, %r1114, %r1114, 14;
	add.s32 	%r891, %r887, %r1115;
	// begin inline asm
	lop3.b32 %r880, %r891, %r887, %r883, 228;
	// end inline asm
	add.s32 	%r1116, %r39, %r880;
	add.s32 	%r1117, %r1116, %r879;
	shf.l.wrap.b32 	%r1118, %r1117, %r1117, 20;
	add.s32 	%r895, %r1118, %r891;
	// begin inline asm
	lop3.b32 %r884, %r895, %r891, %r887, 228;
	// end inline asm
	add.s32 	%r1119, %r40, %r884;
	add.s32 	%r1120, %r1119, %r883;
	shf.l.wrap.b32 	%r1121, %r1120, %r1120, 5;
	add.s32 	%r899, %r1121, %r895;
	// begin inline asm
	lop3.b32 %r888, %r899, %r895, %r891, 228;
	// end inline asm
	add.s32 	%r1122, %r41, %r888;
	add.s32 	%r1123, %r1122, %r887;
	shf.l.wrap.b32 	%r1124, %r1123, %r1123, 9;
	add.s32 	%r903, %r1124, %r899;
	// begin inline asm
	lop3.b32 %r892, %r903, %r899, %r895, 228;
	// end inline asm
	add.s32 	%r1125, %r3558, %r892;
	add.s32 	%r1126, %r1125, %r891;
	add.s32 	%r1127, %r1126, 84369917;
	shf.l.wrap.b32 	%r1128, %r1127, %r1127, 14;
	add.s32 	%r907, %r1128, %r903;
	// begin inline asm
	lop3.b32 %r896, %r907, %r903, %r899, 228;
	// end inline asm
	add.s32 	%r1129, %r42, %r896;
	add.s32 	%r1130, %r1129, %r895;
	shf.l.wrap.b32 	%r1131, %r1130, %r1130, 20;
	add.s32 	%r911, %r1131, %r907;
	// begin inline asm
	lop3.b32 %r900, %r911, %r907, %r903, 228;
	// end inline asm
	add.s32 	%r1132, %r43, %r900;
	add.s32 	%r1133, %r1132, %r899;
	shf.l.wrap.b32 	%r1134, %r1133, %r1133, 5;
	add.s32 	%r915, %r1134, %r911;
	// begin inline asm
	lop3.b32 %r904, %r915, %r911, %r907, 228;
	// end inline asm
	add.s32 	%r1135, %r3557, %r904;
	add.s32 	%r1136, %r1135, %r903;
	add.s32 	%r1137, %r1136, -1783987978;
	shf.l.wrap.b32 	%r1138, %r1137, %r1137, 9;
	add.s32 	%r919, %r1138, %r915;
	// begin inline asm
	lop3.b32 %r908, %r919, %r915, %r911, 228;
	// end inline asm
	add.s32 	%r1139, %r44, %r908;
	add.s32 	%r1140, %r1139, %r907;
	shf.l.wrap.b32 	%r1141, %r1140, %r1140, 14;
	add.s32 	%r923, %r1141, %r919;
	// begin inline asm
	lop3.b32 %r912, %r923, %r919, %r915, 228;
	// end inline asm
	add.s32 	%r1142, %r45, %r912;
	add.s32 	%r1143, %r1142, %r911;
	shf.l.wrap.b32 	%r1144, %r1143, %r1143, 20;
	add.s32 	%r927, %r1144, %r923;
	// begin inline asm
	lop3.b32 %r916, %r927, %r923, %r919, 150;
	// end inline asm
	add.s32 	%r1145, %r46, %r916;
	add.s32 	%r1146, %r1145, %r915;
	shf.l.wrap.b32 	%r1147, %r1146, %r1146, 4;
	add.s32 	%r931, %r1147, %r927;
	// begin inline asm
	lop3.b32 %r920, %r931, %r927, %r923, 150;
	// end inline asm
	add.s32 	%r1148, %r47, %r920;
	add.s32 	%r1149, %r1148, %r919;
	shf.l.wrap.b32 	%r1150, %r1149, %r1149, 11;
	add.s32 	%r935, %r1150, %r931;
	// begin inline asm
	lop3.b32 %r924, %r935, %r931, %r927, 150;
	// end inline asm
	add.s32 	%r1151, %r48, %r924;
	add.s32 	%r1152, %r1151, %r923;
	shf.l.wrap.b32 	%r1153, %r1152, %r1152, 16;
	add.s32 	%r939, %r1153, %r935;
	// begin inline asm
	lop3.b32 %r928, %r939, %r935, %r931, 150;
	// end inline asm
	add.s32 	%r1154, %r49, %r928;
	add.s32 	%r1155, %r1154, %r927;
	shf.l.wrap.b32 	%r1156, %r1155, %r1155, 23;
	add.s32 	%r943, %r1156, %r939;
	// begin inline asm
	lop3.b32 %r932, %r943, %r939, %r935, 150;
	// end inline asm
	add.s32 	%r1157, %r3556, %r932;
	add.s32 	%r1158, %r1157, %r931;
	add.s32 	%r1159, %r1158, -1802725939;
	shf.l.wrap.b32 	%r1160, %r1159, %r1159, 4;
	add.s32 	%r947, %r1160, %r943;
	// begin inline asm
	lop3.b32 %r936, %r947, %r943, %r939, 150;
	// end inline asm
	add.s32 	%r1161, %r50, %r936;
	add.s32 	%r1162, %r1161, %r935;
	shf.l.wrap.b32 	%r1163, %r1162, %r1162, 11;
	add.s32 	%r951, %r1163, %r947;
	// begin inline asm
	lop3.b32 %r940, %r951, %r947, %r943, 150;
	// end inline asm
	add.s32 	%r1164, %r51, %r940;
	add.s32 	%r1165, %r1164, %r939;
	shf.l.wrap.b32 	%r1166, %r1165, %r1165, 16;
	add.s32 	%r955, %r1166, %r951;
	// begin inline asm
	lop3.b32 %r944, %r955, %r951, %r947, 150;
	// end inline asm
	add.s32 	%r1167, %r52, %r944;
	add.s32 	%r1168, %r1167, %r943;
	shf.l.wrap.b32 	%r1169, %r1168, %r1168, 23;
	add.s32 	%r959, %r1169, %r955;
	// begin inline asm
	lop3.b32 %r948, %r959, %r955, %r951, 150;
	// end inline asm
	add.s32 	%r1170, %r53, %r948;
	add.s32 	%r1171, %r1170, %r947;
	shf.l.wrap.b32 	%r1172, %r1171, %r1171, 4;
	add.s32 	%r963, %r1172, %r959;
	// begin inline asm
	lop3.b32 %r952, %r963, %r959, %r955, 150;
	// end inline asm
	add.s32 	%r1173, %r3555, %r952;
	add.s32 	%r1174, %r1173, %r951;
	add.s32 	%r1175, %r1174, 1374046971;
	shf.l.wrap.b32 	%r1176, %r1175, %r1175, 11;
	add.s32 	%r967, %r1176, %r963;
	// begin inline asm
	lop3.b32 %r956, %r967, %r963, %r959, 150;
	// end inline asm
	add.s32 	%r1177, %r3558, %r956;
	add.s32 	%r1178, %r1177, %r955;
	add.s32 	%r1179, %r1178, -450788101;
	shf.l.wrap.b32 	%r1180, %r1179, %r1179, 16;
	add.s32 	%r971, %r1180, %r967;
	// begin inline asm
	lop3.b32 %r960, %r971, %r967, %r963, 150;
	// end inline asm
	add.s32 	%r1181, %r54, %r960;
	add.s32 	%r1182, %r1181, %r959;
	shf.l.wrap.b32 	%r1183, %r1182, %r1182, 23;
	add.s32 	%r975, %r1183, %r971;
	// begin inline asm
	lop3.b32 %r964, %r975, %r971, %r967, 150;
	// end inline asm
	add.s32 	%r1184, %r55, %r964;
	add.s32 	%r1185, %r1184, %r963;
	shf.l.wrap.b32 	%r1186, %r1185, %r1185, 4;
	add.s32 	%r979, %r1186, %r975;
	// begin inline asm
	lop3.b32 %r968, %r979, %r975, %r971, 150;
	// end inline asm
	add.s32 	%r1187, %r56, %r968;
	add.s32 	%r1188, %r1187, %r967;
	shf.l.wrap.b32 	%r1189, %r1188, %r1188, 11;
	add.s32 	%r983, %r1189, %r979;
	// begin inline asm
	lop3.b32 %r972, %r983, %r979, %r975, 150;
	// end inline asm
	add.s32 	%r1190, %r972, %r971;
	add.s32 	%r1191, %r1190, 530742520;
	shf.l.wrap.b32 	%r1192, %r1191, %r1191, 16;
	add.s32 	%r987, %r983, %r1192;
	// begin inline asm
	lop3.b32 %r976, %r987, %r983, %r979, 150;
	// end inline asm
	add.s32 	%r1193, %r3557, %r976;
	add.s32 	%r1194, %r1193, %r975;
	add.s32 	%r1195, %r1194, 1567044451;
	shf.l.wrap.b32 	%r1196, %r1195, %r1195, 23;
	add.s32 	%r991, %r1196, %r987;
	// begin inline asm
	lop3.b32 %r980, %r991, %r987, %r983, 57;
	// end inline asm
	add.s32 	%r1197, %r3555, %r980;
	add.s32 	%r1198, %r1197, %r979;
	add.s32 	%r1199, %r1198, 1533953349;
	shf.l.wrap.b32 	%r1200, %r1199, %r1199, 6;
	add.s32 	%r995, %r1200, %r991;
	// begin inline asm
	lop3.b32 %r984, %r995, %r991, %r987, 57;
	// end inline asm
	add.s32 	%r1201, %r57, %r984;
	add.s32 	%r1202, %r1201, %r983;
	shf.l.wrap.b32 	%r1203, %r1202, %r1202, 10;
	add.s32 	%r999, %r1203, %r995;
	// begin inline asm
	lop3.b32 %r988, %r999, %r995, %r991, 57;
	// end inline asm
	add.s32 	%r1204, %r58, %r988;
	add.s32 	%r1205, %r1204, %r987;
	shf.l.wrap.b32 	%r1206, %r1205, %r1205, 15;
	add.s32 	%r1003, %r1206, %r999;
	// begin inline asm
	lop3.b32 %r992, %r1003, %r999, %r995, 57;
	// end inline asm
	add.s32 	%r1207, %r59, %r992;
	add.s32 	%r1208, %r1207, %r991;
	shf.l.wrap.b32 	%r1209, %r1208, %r1208, 21;
	add.s32 	%r1007, %r1209, %r1003;
	// begin inline asm
	lop3.b32 %r996, %r1007, %r1003, %r999, 57;
	// end inline asm
	add.s32 	%r1210, %r60, %r996;
	add.s32 	%r1211, %r1210, %r995;
	shf.l.wrap.b32 	%r1212, %r1211, %r1211, 6;
	add.s32 	%r1011, %r1212, %r1007;
	// begin inline asm
	lop3.b32 %r1000, %r1011, %r1007, %r1003, 57;
	// end inline asm
	add.s32 	%r1213, %r3558, %r1000;
	add.s32 	%r1214, %r1213, %r999;
	add.s32 	%r1215, %r1214, -1623252728;
	shf.l.wrap.b32 	%r1216, %r1215, %r1215, 10;
	add.s32 	%r1015, %r1216, %r1011;
	// begin inline asm
	lop3.b32 %r1004, %r1015, %r1011, %r1007, 57;
	// end inline asm
	add.s32 	%r1217, %r61, %r1004;
	add.s32 	%r1218, %r1217, %r1003;
	shf.l.wrap.b32 	%r1219, %r1218, %r1218, 15;
	add.s32 	%r1019, %r1219, %r1015;
	// begin inline asm
	lop3.b32 %r1008, %r1019, %r1015, %r1011, 57;
	// end inline asm
	add.s32 	%r1220, %r3556, %r1008;
	add.s32 	%r1221, %r1220, %r1007;
	add.s32 	%r1222, %r1221, 1968310618;
	shf.l.wrap.b32 	%r1223, %r1222, %r1222, 21;
	add.s32 	%r1023, %r1223, %r1019;
	// begin inline asm
	lop3.b32 %r1012, %r1023, %r1019, %r1015, 57;
	// end inline asm
	add.s32 	%r1224, %r62, %r1012;
	add.s32 	%r1225, %r1224, %r1011;
	shf.l.wrap.b32 	%r1226, %r1225, %r1225, 6;
	add.s32 	%r1027, %r1226, %r1023;
	// begin inline asm
	lop3.b32 %r1016, %r1027, %r1023, %r1019, 57;
	// end inline asm
	add.s32 	%r1227, %r1016, %r1015;
	add.s32 	%r1228, %r1227, -30611744;
	shf.l.wrap.b32 	%r1229, %r1228, %r1228, 10;
	add.s32 	%r1031, %r1229, %r1027;
	// begin inline asm
	lop3.b32 %r1020, %r1031, %r1027, %r1023, 57;
	// end inline asm
	add.s32 	%r1230, %r63, %r1020;
	add.s32 	%r1231, %r1230, %r1019;
	shf.l.wrap.b32 	%r1232, %r1231, %r1231, 15;
	add.s32 	%r1035, %r1232, %r1031;
	// begin inline asm
	lop3.b32 %r1024, %r1035, %r1031, %r1027, 57;
	// end inline asm
	add.s32 	%r1233, %r64, %r1024;
	add.s32 	%r1234, %r1233, %r1023;
	shf.l.wrap.b32 	%r1235, %r1234, %r1234, 21;
	add.s32 	%r1039, %r1235, %r1035;
	// begin inline asm
	lop3.b32 %r1028, %r1039, %r1035, %r1031, 57;
	// end inline asm
	add.s32 	%r1236, %r65, %r1028;
	add.s32 	%r1237, %r1236, %r1027;
	shf.l.wrap.b32 	%r1238, %r1237, %r1237, 6;
	add.s32 	%r3555, %r1238, %r1039;
	// begin inline asm
	lop3.b32 %r1032, %r3555, %r1039, %r1035, 57;
	// end inline asm
	add.s32 	%r1239, %r66, %r1032;
	add.s32 	%r1240, %r1239, %r1031;
	shf.l.wrap.b32 	%r1241, %r1240, %r1240, 10;
	add.s32 	%r3558, %r1241, %r3555;
	// begin inline asm
	lop3.b32 %r1036, %r3558, %r3555, %r1039, 57;
	// end inline asm
	add.s32 	%r1242, %r3557, %r1036;
	add.s32 	%r1243, %r1242, %r1035;
	add.s32 	%r1244, %r1243, -1013796935;
	shf.l.wrap.b32 	%r1245, %r1244, %r1244, 15;
	add.s32 	%r3557, %r1245, %r3558;
	// begin inline asm
	lop3.b32 %r1040, %r3557, %r3558, %r3555, 57;
	// end inline asm
	add.s32 	%r1246, %r67, %r1040;
	add.s32 	%r1247, %r1246, %r1039;
	shf.l.wrap.b32 	%r1248, %r1247, %r1247, 21;
	add.s32 	%r3556, %r1248, %r3557;
	add.s32 	%r2, %r2, -1;
	setp.eq.s32 	%p15, %r2, 0;
	@%p15 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_14;

$L__BB0_25:
	ld.param.u64 	%rd26, [phpass_param_1];
	shl.b64 	%rd24, %rd1, 4;
	add.s64 	%rd25, %rd26, %rd24;
	add.s32 	%r3514, %r3555, 1732584193;
	st.global.u32 	[%rd25], %r3514;
	add.s32 	%r3515, %r3556, -271733879;
	st.global.u32 	[%rd25+4], %r3515;
	add.s32 	%r3516, %r3557, -1732584194;
	st.global.u32 	[%rd25+8], %r3516;
	add.s32 	%r3517, %r3558, 271733878;
	st.global.u32 	[%rd25+12], %r3517;
	ret;

}

  